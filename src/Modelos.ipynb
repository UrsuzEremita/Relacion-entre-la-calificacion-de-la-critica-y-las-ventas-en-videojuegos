{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from fitter import Fitter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import time\n",
    "\n",
    "import synthgauge as sg\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n64na = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/n64na.csv', index_col=0)\n",
    "n64eu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/n64eu.csv', index_col=0)\n",
    "n64jp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/n64jp.csv', index_col=0)\n",
    "wiina = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/wiina.csv', index_col=0)\n",
    "ds3eu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ds3eu.csv', index_col=0)\n",
    "ds3jp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ds3jp.csv', index_col=0)\n",
    "ds3na = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ds3na.csv', index_col=0)\n",
    "dseu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/dseu.csv', index_col=0)\n",
    "dsjp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/dsjp.csv', index_col=0)\n",
    "dsna = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/dsna.csv', index_col=0)\n",
    "gbaeu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/gbaeu.csv', index_col=0)\n",
    "gbajp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/gbajp.csv', index_col=0)\n",
    "gbana = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/gbana.csv', index_col=0)\n",
    "gceu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/gceu.csv', index_col=0)\n",
    "gcjp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/gcjp.csv', index_col=0)\n",
    "gcna = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/gcna.csv', index_col=0)\n",
    "pceu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/pceu.csv', index_col=0)\n",
    "pcna = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/pcna.csv', index_col=0)\n",
    "ps2eu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ps2eu.csv', index_col=0)\n",
    "ps2jp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ps2jp.csv', index_col=0)\n",
    "ps2na = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ps2na.csv', index_col=0)\n",
    "ps3eu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ps3eu.csv', index_col=0)\n",
    "ps3jp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ps3jp.csv', index_col=0)\n",
    "ps3na = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ps3na.csv', index_col=0)\n",
    "ps4eu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ps4eu.csv', index_col=0)\n",
    "ps4jp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ps4jp.csv', index_col=0)\n",
    "ps4na = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/ps4na.csv', index_col=0)\n",
    "pseu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/pseu.csv', index_col=0)\n",
    "psjp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/psjp.csv', index_col=0)\n",
    "psna = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/psna.csv', index_col=0)\n",
    "pspeu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/pspeu.csv', index_col=0)\n",
    "pspjp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/pspjp.csv', index_col=0)\n",
    "pspna = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/pspna.csv', index_col=0)\n",
    "psveu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/psveu.csv', index_col=0)\n",
    "psvjp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/psvjp.csv', index_col=0)\n",
    "psvna = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/psvna.csv', index_col=0)\n",
    "wiieu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/wiieu.csv', index_col=0)\n",
    "wiijp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/wiijp.csv', index_col=0)\n",
    "wiiueu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/wiiueu.csv', index_col=0)\n",
    "wiiujp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/wiiujp.csv', index_col=0)\n",
    "wiiuna = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/wiiuna.csv', index_col=0)\n",
    "x360eu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/x360eu.csv', index_col=0)\n",
    "x360jp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/x360jp.csv', index_col=0)\n",
    "x360na = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/x360na.csv', index_col=0)\n",
    "xbeu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/xbeu.csv', index_col=0)\n",
    "xbjp = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/xbjp.csv', index_col=0)\n",
    "xbna = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/xbna.csv', index_col=0)\n",
    "xoneeu = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/xoneeu.csv', index_col=0)\n",
    "xonena = pd.read_csv('C:/Users/ursuz/OneDrive/Escritorio/Tesis/xonena.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 39, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 1274871.794872\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:150: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 245, in _count_physical_cores\n",
      "    raise ValueError(\n"
     ]
    }
   ],
   "source": [
    "X = n64na['Calificacion_critica']\n",
    "y = n64na['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>9.184374e+05</td>\n",
       "      <td>7.532826e+05</td>\n",
       "      <td>8.588228e+05</td>\n",
       "      <td>9.761765e+05</td>\n",
       "      <td>8.191103e+05</td>\n",
       "      <td>8.159291e+05</td>\n",
       "      <td>8.388235e+05</td>\n",
       "      <td>1.027840e+06</td>\n",
       "      <td>9.270699e+05</td>\n",
       "      <td>1.141991e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.463379e+12</td>\n",
       "      <td>1.145030e+12</td>\n",
       "      <td>2.092242e+12</td>\n",
       "      <td>2.976949e+12</td>\n",
       "      <td>1.645795e+12</td>\n",
       "      <td>1.995351e+12</td>\n",
       "      <td>1.152448e+12</td>\n",
       "      <td>3.065554e+12</td>\n",
       "      <td>2.870133e+12</td>\n",
       "      <td>2.069997e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.209702e+06</td>\n",
       "      <td>1.070061e+06</td>\n",
       "      <td>1.446458e+06</td>\n",
       "      <td>1.725384e+06</td>\n",
       "      <td>1.282886e+06</td>\n",
       "      <td>1.412569e+06</td>\n",
       "      <td>1.073522e+06</td>\n",
       "      <td>1.750872e+06</td>\n",
       "      <td>1.694147e+06</td>\n",
       "      <td>1.438748e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>2.716493e-01</td>\n",
       "      <td>4.300973e-01</td>\n",
       "      <td>-4.134771e-02</td>\n",
       "      <td>-4.816826e-01</td>\n",
       "      <td>1.808570e-01</td>\n",
       "      <td>6.876596e-03</td>\n",
       "      <td>4.264050e-01</td>\n",
       "      <td>-5.257831e-01</td>\n",
       "      <td>-4.285187e-01</td>\n",
       "      <td>-3.027600e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           9.184374e+05  7.532826e+05  8.588228e+05   \n",
       "Error Cuadrado Promedio           1.463379e+12  1.145030e+12  2.092242e+12   \n",
       "Raíz del Error Cuadrado Promedio  1.209702e+06  1.070061e+06  1.446458e+06   \n",
       "R2                                2.716493e-01  4.300973e-01 -4.134771e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  9.761765e+05      8.191103e+05   \n",
       "Error Cuadrado Promedio                  2.976949e+12      1.645795e+12   \n",
       "Raíz del Error Cuadrado Promedio         1.725384e+06      1.282886e+06   \n",
       "R2                                      -4.816826e-01      1.808570e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           8.159291e+05         8.388235e+05   \n",
       "Error Cuadrado Promedio           1.995351e+12         1.152448e+12   \n",
       "Raíz del Error Cuadrado Promedio  1.412569e+06         1.073522e+06   \n",
       "R2                                6.876596e-03         4.264050e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     1.027840e+06       9.270699e+05   \n",
       "Error Cuadrado Promedio                     3.065554e+12       2.870133e+12   \n",
       "Raíz del Error Cuadrado Promedio            1.750872e+06       1.694147e+06   \n",
       "R2                                         -5.257831e-01      -4.285187e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           1.141991e+06  \n",
       "Error Cuadrado Promedio           2.069997e+12  \n",
       "Raíz del Error Cuadrado Promedio  1.438748e+06  \n",
       "R2                               -3.027600e-02  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "n64nare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "n64nare.to_csv('n64nare.csv')\n",
    "n64nare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 38, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 449210.526316\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = n64eu['Calificacion_critica']\n",
    "y = n64eu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.732809e+05</td>\n",
       "      <td>2.275393e+05</td>\n",
       "      <td>2.917620e+05</td>\n",
       "      <td>4.405882e+05</td>\n",
       "      <td>3.173297e+05</td>\n",
       "      <td>3.947005e+05</td>\n",
       "      <td>2.489412e+05</td>\n",
       "      <td>3.326087e+05</td>\n",
       "      <td>4.291817e+05</td>\n",
       "      <td>3.602632e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.564849e+11</td>\n",
       "      <td>1.070506e+11</td>\n",
       "      <td>2.356464e+11</td>\n",
       "      <td>6.256324e+11</td>\n",
       "      <td>2.618966e+11</td>\n",
       "      <td>5.597584e+11</td>\n",
       "      <td>9.376424e+10</td>\n",
       "      <td>3.334988e+11</td>\n",
       "      <td>6.059323e+11</td>\n",
       "      <td>2.364099e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>3.955818e+05</td>\n",
       "      <td>3.271858e+05</td>\n",
       "      <td>4.854342e+05</td>\n",
       "      <td>7.909692e+05</td>\n",
       "      <td>5.117584e+05</td>\n",
       "      <td>7.481701e+05</td>\n",
       "      <td>3.062095e+05</td>\n",
       "      <td>5.774936e+05</td>\n",
       "      <td>7.784165e+05</td>\n",
       "      <td>4.862200e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>2.979317e-01</td>\n",
       "      <td>5.197187e-01</td>\n",
       "      <td>-5.722547e-02</td>\n",
       "      <td>-1.806894e+00</td>\n",
       "      <td>-1.749968e-01</td>\n",
       "      <td>-1.511351e+00</td>\n",
       "      <td>5.793276e-01</td>\n",
       "      <td>-4.962395e-01</td>\n",
       "      <td>-1.718510e+00</td>\n",
       "      <td>-6.065090e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.732809e+05  2.275393e+05  2.917620e+05   \n",
       "Error Cuadrado Promedio           1.564849e+11  1.070506e+11  2.356464e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.955818e+05  3.271858e+05  4.854342e+05   \n",
       "R2                                2.979317e-01  5.197187e-01 -5.722547e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  4.405882e+05      3.173297e+05   \n",
       "Error Cuadrado Promedio                  6.256324e+11      2.618966e+11   \n",
       "Raíz del Error Cuadrado Promedio         7.909692e+05      5.117584e+05   \n",
       "R2                                      -1.806894e+00     -1.749968e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           3.947005e+05         2.489412e+05   \n",
       "Error Cuadrado Promedio           5.597584e+11         9.376424e+10   \n",
       "Raíz del Error Cuadrado Promedio  7.481701e+05         3.062095e+05   \n",
       "R2                               -1.511351e+00         5.793276e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     3.326087e+05       4.291817e+05   \n",
       "Error Cuadrado Promedio                     3.334988e+11       6.059323e+11   \n",
       "Raíz del Error Cuadrado Promedio            5.774936e+05       7.784165e+05   \n",
       "R2                                         -4.962395e-01      -1.718510e+00   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           3.602632e+05  \n",
       "Error Cuadrado Promedio           2.364099e+11  \n",
       "Raíz del Error Cuadrado Promedio  4.862200e+05  \n",
       "R2                               -6.065090e-02  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "n64eure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "n64eure.to_csv('n64eure.csv')\n",
    "n64eure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 26, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 575769.230769\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = n64jp['Calificacion_critica']\n",
    "y = n64jp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>4.451461e+05</td>\n",
       "      <td>4.357970e+05</td>\n",
       "      <td>4.366670e+05</td>\n",
       "      <td>8.016667e+05</td>\n",
       "      <td>7.097969e+05</td>\n",
       "      <td>9.649985e+05</td>\n",
       "      <td>4.551667e+05</td>\n",
       "      <td>5.821633e+05</td>\n",
       "      <td>7.967802e+05</td>\n",
       "      <td>4.358333e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>3.627878e+11</td>\n",
       "      <td>3.808044e+11</td>\n",
       "      <td>4.323762e+11</td>\n",
       "      <td>1.220467e+12</td>\n",
       "      <td>8.228753e+11</td>\n",
       "      <td>1.514345e+12</td>\n",
       "      <td>4.389810e+11</td>\n",
       "      <td>6.886390e+11</td>\n",
       "      <td>1.189926e+12</td>\n",
       "      <td>3.497641e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>6.023187e+05</td>\n",
       "      <td>6.170935e+05</td>\n",
       "      <td>6.575532e+05</td>\n",
       "      <td>1.104747e+06</td>\n",
       "      <td>9.071248e+05</td>\n",
       "      <td>1.230587e+06</td>\n",
       "      <td>6.625564e+05</td>\n",
       "      <td>8.298428e+05</td>\n",
       "      <td>1.090837e+06</td>\n",
       "      <td>5.914085e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-3.737013e-02</td>\n",
       "      <td>-8.888747e-02</td>\n",
       "      <td>-2.363540e-01</td>\n",
       "      <td>-2.489852e+00</td>\n",
       "      <td>-1.352963e+00</td>\n",
       "      <td>-3.330179e+00</td>\n",
       "      <td>-2.552401e-01</td>\n",
       "      <td>-9.691223e-01</td>\n",
       "      <td>-2.402522e+00</td>\n",
       "      <td>-1.295420e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           4.451461e+05  4.357970e+05  4.366670e+05   \n",
       "Error Cuadrado Promedio           3.627878e+11  3.808044e+11  4.323762e+11   \n",
       "Raíz del Error Cuadrado Promedio  6.023187e+05  6.170935e+05  6.575532e+05   \n",
       "R2                               -3.737013e-02 -8.888747e-02 -2.363540e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  8.016667e+05      7.097969e+05   \n",
       "Error Cuadrado Promedio                  1.220467e+12      8.228753e+11   \n",
       "Raíz del Error Cuadrado Promedio         1.104747e+06      9.071248e+05   \n",
       "R2                                      -2.489852e+00     -1.352963e+00   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           9.649985e+05         4.551667e+05   \n",
       "Error Cuadrado Promedio           1.514345e+12         4.389810e+11   \n",
       "Raíz del Error Cuadrado Promedio  1.230587e+06         6.625564e+05   \n",
       "R2                               -3.330179e+00        -2.552401e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     5.821633e+05       7.967802e+05   \n",
       "Error Cuadrado Promedio                     6.886390e+11       1.189926e+12   \n",
       "Raíz del Error Cuadrado Promedio            8.298428e+05       1.090837e+06   \n",
       "R2                                         -9.691223e-01      -2.402522e+00   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           4.358333e+05  \n",
       "Error Cuadrado Promedio           3.497641e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.914085e+05  \n",
       "R2                               -1.295420e-04  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "n64jpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "n64jpre.to_csv('n64jpre.csv')\n",
    "n64jpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 56\n",
      "[LightGBM] [Info] Number of data points in the train set: 406, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 542807.881773\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = wiina['Calificacion_critica']\n",
    "y = wiina['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>8.362208e+05</td>\n",
       "      <td>8.150642e+05</td>\n",
       "      <td>7.487806e+05</td>\n",
       "      <td>8.658082e+05</td>\n",
       "      <td>8.646313e+05</td>\n",
       "      <td>8.657283e+05</td>\n",
       "      <td>8.995057e+05</td>\n",
       "      <td>8.506500e+05</td>\n",
       "      <td>8.492494e+05</td>\n",
       "      <td>8.506579e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.234036e+13</td>\n",
       "      <td>1.229379e+13</td>\n",
       "      <td>1.290460e+13</td>\n",
       "      <td>1.242881e+13</td>\n",
       "      <td>1.244838e+13</td>\n",
       "      <td>1.242874e+13</td>\n",
       "      <td>1.283365e+13</td>\n",
       "      <td>1.322783e+13</td>\n",
       "      <td>1.244672e+13</td>\n",
       "      <td>1.248290e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>3.512885e+06</td>\n",
       "      <td>3.506250e+06</td>\n",
       "      <td>3.592297e+06</td>\n",
       "      <td>3.525452e+06</td>\n",
       "      <td>3.528226e+06</td>\n",
       "      <td>3.525442e+06</td>\n",
       "      <td>3.582408e+06</td>\n",
       "      <td>3.637008e+06</td>\n",
       "      <td>3.527991e+06</td>\n",
       "      <td>3.533115e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.314389e-02</td>\n",
       "      <td>1.686789e-02</td>\n",
       "      <td>-3.197847e-02</td>\n",
       "      <td>6.070060e-03</td>\n",
       "      <td>4.505810e-03</td>\n",
       "      <td>6.075850e-03</td>\n",
       "      <td>-2.630429e-02</td>\n",
       "      <td>-5.782668e-02</td>\n",
       "      <td>4.638382e-03</td>\n",
       "      <td>1.744744e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           8.362208e+05  8.150642e+05  7.487806e+05   \n",
       "Error Cuadrado Promedio           1.234036e+13  1.229379e+13  1.290460e+13   \n",
       "Raíz del Error Cuadrado Promedio  3.512885e+06  3.506250e+06  3.592297e+06   \n",
       "R2                                1.314389e-02  1.686789e-02 -3.197847e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  8.658082e+05      8.646313e+05   \n",
       "Error Cuadrado Promedio                  1.242881e+13      1.244838e+13   \n",
       "Raíz del Error Cuadrado Promedio         3.525452e+06      3.528226e+06   \n",
       "R2                                       6.070060e-03      4.505810e-03   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           8.657283e+05         8.995057e+05   \n",
       "Error Cuadrado Promedio           1.242874e+13         1.283365e+13   \n",
       "Raíz del Error Cuadrado Promedio  3.525442e+06         3.582408e+06   \n",
       "R2                                6.075850e-03        -2.630429e-02   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     8.506500e+05       8.492494e+05   \n",
       "Error Cuadrado Promedio                     1.322783e+13       1.244672e+13   \n",
       "Raíz del Error Cuadrado Promedio            3.637008e+06       3.527991e+06   \n",
       "R2                                         -5.782668e-02       4.638382e-03   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           8.506579e+05  \n",
       "Error Cuadrado Promedio           1.248290e+13  \n",
       "Raíz del Error Cuadrado Promedio  3.533115e+06  \n",
       "R2                                1.744744e-03  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "wiinare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "wiinare.to_csv('wiinare.csv')\n",
    "wiinare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26\n",
      "[LightGBM] [Info] Number of data points in the train set: 95, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 238421.052632\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ds3eu['Calificacion_critica']\n",
    "y = ds3eu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.387895e+05</td>\n",
       "      <td>2.257170e+05</td>\n",
       "      <td>2.176177e+05</td>\n",
       "      <td>2.415278e+05</td>\n",
       "      <td>2.349719e+05</td>\n",
       "      <td>2.415252e+05</td>\n",
       "      <td>1.867143e+05</td>\n",
       "      <td>2.639922e+05</td>\n",
       "      <td>2.320608e+05</td>\n",
       "      <td>2.505373e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.326535e+11</td>\n",
       "      <td>2.267905e+11</td>\n",
       "      <td>3.032811e+11</td>\n",
       "      <td>3.411691e+11</td>\n",
       "      <td>3.354790e+11</td>\n",
       "      <td>3.411652e+11</td>\n",
       "      <td>2.600690e+11</td>\n",
       "      <td>3.389923e+11</td>\n",
       "      <td>3.320152e+11</td>\n",
       "      <td>2.292559e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>4.823417e+05</td>\n",
       "      <td>4.762253e+05</td>\n",
       "      <td>5.507097e+05</td>\n",
       "      <td>5.840968e+05</td>\n",
       "      <td>5.792054e+05</td>\n",
       "      <td>5.840935e+05</td>\n",
       "      <td>5.099697e+05</td>\n",
       "      <td>5.822304e+05</td>\n",
       "      <td>5.762076e+05</td>\n",
       "      <td>4.788067e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.361437e-01</td>\n",
       "      <td>1.579135e-01</td>\n",
       "      <td>-1.261007e-01</td>\n",
       "      <td>-2.667809e-01</td>\n",
       "      <td>-2.456531e-01</td>\n",
       "      <td>-2.667666e-01</td>\n",
       "      <td>3.434832e-02</td>\n",
       "      <td>-2.586983e-01</td>\n",
       "      <td>-2.327919e-01</td>\n",
       "      <td>1.487595e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.387895e+05  2.257170e+05  2.176177e+05   \n",
       "Error Cuadrado Promedio           2.326535e+11  2.267905e+11  3.032811e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.823417e+05  4.762253e+05  5.507097e+05   \n",
       "R2                                1.361437e-01  1.579135e-01 -1.261007e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.415278e+05      2.349719e+05   \n",
       "Error Cuadrado Promedio                  3.411691e+11      3.354790e+11   \n",
       "Raíz del Error Cuadrado Promedio         5.840968e+05      5.792054e+05   \n",
       "R2                                      -2.667809e-01     -2.456531e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.415252e+05         1.867143e+05   \n",
       "Error Cuadrado Promedio           3.411652e+11         2.600690e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.840935e+05         5.099697e+05   \n",
       "R2                               -2.667666e-01         3.434832e-02   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.639922e+05       2.320608e+05   \n",
       "Error Cuadrado Promedio                     3.389923e+11       3.320152e+11   \n",
       "Raíz del Error Cuadrado Promedio            5.822304e+05       5.762076e+05   \n",
       "R2                                         -2.586983e-01      -2.327919e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.505373e+05  \n",
       "Error Cuadrado Promedio           2.292559e+11  \n",
       "Raíz del Error Cuadrado Promedio  4.788067e+05  \n",
       "R2                                1.487595e-01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ds3eure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ds3eure.to_csv('ds3eure.csv')\n",
    "ds3eure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20\n",
      "[LightGBM] [Info] Number of data points in the train set: 75, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 358800.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ds3jp['Calificacion_critica']\n",
    "y = ds3jp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.352879e+05</td>\n",
       "      <td>3.185985e+05</td>\n",
       "      <td>1.796929e+05</td>\n",
       "      <td>2.487475e+05</td>\n",
       "      <td>2.423809e+05</td>\n",
       "      <td>2.478345e+05</td>\n",
       "      <td>2.885455e+05</td>\n",
       "      <td>2.152102e+05</td>\n",
       "      <td>2.453718e+05</td>\n",
       "      <td>2.880779e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.304100e+11</td>\n",
       "      <td>2.871061e+11</td>\n",
       "      <td>1.848885e+11</td>\n",
       "      <td>3.265781e+11</td>\n",
       "      <td>2.727478e+11</td>\n",
       "      <td>3.265240e+11</td>\n",
       "      <td>3.201124e+11</td>\n",
       "      <td>2.255023e+11</td>\n",
       "      <td>3.197553e+11</td>\n",
       "      <td>2.684340e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>4.800104e+05</td>\n",
       "      <td>5.358228e+05</td>\n",
       "      <td>4.299866e+05</td>\n",
       "      <td>5.714701e+05</td>\n",
       "      <td>5.222526e+05</td>\n",
       "      <td>5.714228e+05</td>\n",
       "      <td>5.657847e+05</td>\n",
       "      <td>4.748709e+05</td>\n",
       "      <td>5.654691e+05</td>\n",
       "      <td>5.181062e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-2.858094e-01</td>\n",
       "      <td>-6.022040e-01</td>\n",
       "      <td>-3.177531e-02</td>\n",
       "      <td>-8.224785e-01</td>\n",
       "      <td>-5.220769e-01</td>\n",
       "      <td>-8.221765e-01</td>\n",
       "      <td>-7.863962e-01</td>\n",
       "      <td>-2.584223e-01</td>\n",
       "      <td>-7.844038e-01</td>\n",
       "      <td>-4.980036e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.352879e+05  3.185985e+05  1.796929e+05   \n",
       "Error Cuadrado Promedio           2.304100e+11  2.871061e+11  1.848885e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.800104e+05  5.358228e+05  4.299866e+05   \n",
       "R2                               -2.858094e-01 -6.022040e-01 -3.177531e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.487475e+05      2.423809e+05   \n",
       "Error Cuadrado Promedio                  3.265781e+11      2.727478e+11   \n",
       "Raíz del Error Cuadrado Promedio         5.714701e+05      5.222526e+05   \n",
       "R2                                      -8.224785e-01     -5.220769e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.478345e+05         2.885455e+05   \n",
       "Error Cuadrado Promedio           3.265240e+11         3.201124e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.714228e+05         5.657847e+05   \n",
       "R2                               -8.221765e-01        -7.863962e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.152102e+05       2.453718e+05   \n",
       "Error Cuadrado Promedio                     2.255023e+11       3.197553e+11   \n",
       "Raíz del Error Cuadrado Promedio            4.748709e+05       5.654691e+05   \n",
       "R2                                         -2.584223e-01      -7.844038e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.880779e+05  \n",
       "Error Cuadrado Promedio           2.684340e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.181062e+05  \n",
       "R2                               -4.980036e-01  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ds3jpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ds3jpre.to_csv('ds3jpre.csv')\n",
    "ds3jpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26\n",
      "[LightGBM] [Info] Number of data points in the train set: 106, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 381792.452830\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ds3na['Calificacion_critica']\n",
    "y = ds3na['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.318867e+05</td>\n",
       "      <td>1.771767e+05</td>\n",
       "      <td>1.165182e+05</td>\n",
       "      <td>1.923913e+05</td>\n",
       "      <td>2.012565e+05</td>\n",
       "      <td>1.934338e+05</td>\n",
       "      <td>2.481739e+05</td>\n",
       "      <td>1.932067e+05</td>\n",
       "      <td>1.749027e+05</td>\n",
       "      <td>1.833347e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>7.198187e+10</td>\n",
       "      <td>5.688785e+10</td>\n",
       "      <td>2.625665e+10</td>\n",
       "      <td>9.555336e+10</td>\n",
       "      <td>1.098117e+11</td>\n",
       "      <td>9.596032e+10</td>\n",
       "      <td>1.262350e+11</td>\n",
       "      <td>6.246048e+10</td>\n",
       "      <td>8.489049e+10</td>\n",
       "      <td>6.370061e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>2.682944e+05</td>\n",
       "      <td>2.385117e+05</td>\n",
       "      <td>1.620390e+05</td>\n",
       "      <td>3.091171e+05</td>\n",
       "      <td>3.313784e+05</td>\n",
       "      <td>3.097746e+05</td>\n",
       "      <td>3.552956e+05</td>\n",
       "      <td>2.499209e+05</td>\n",
       "      <td>2.913597e+05</td>\n",
       "      <td>2.523898e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-1.863727e+00</td>\n",
       "      <td>-1.263227e+00</td>\n",
       "      <td>-4.459476e-02</td>\n",
       "      <td>-2.801496e+00</td>\n",
       "      <td>-3.368749e+00</td>\n",
       "      <td>-2.817686e+00</td>\n",
       "      <td>-4.022133e+00</td>\n",
       "      <td>-1.484928e+00</td>\n",
       "      <td>-2.377284e+00</td>\n",
       "      <td>-1.534266e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.318867e+05  1.771767e+05  1.165182e+05   \n",
       "Error Cuadrado Promedio           7.198187e+10  5.688785e+10  2.625665e+10   \n",
       "Raíz del Error Cuadrado Promedio  2.682944e+05  2.385117e+05  1.620390e+05   \n",
       "R2                               -1.863727e+00 -1.263227e+00 -4.459476e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  1.923913e+05      2.012565e+05   \n",
       "Error Cuadrado Promedio                  9.555336e+10      1.098117e+11   \n",
       "Raíz del Error Cuadrado Promedio         3.091171e+05      3.313784e+05   \n",
       "R2                                      -2.801496e+00     -3.368749e+00   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           1.934338e+05         2.481739e+05   \n",
       "Error Cuadrado Promedio           9.596032e+10         1.262350e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.097746e+05         3.552956e+05   \n",
       "R2                               -2.817686e+00        -4.022133e+00   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     1.932067e+05       1.749027e+05   \n",
       "Error Cuadrado Promedio                     6.246048e+10       8.489049e+10   \n",
       "Raíz del Error Cuadrado Promedio            2.499209e+05       2.913597e+05   \n",
       "R2                                         -1.484928e+00      -2.377284e+00   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           1.833347e+05  \n",
       "Error Cuadrado Promedio           6.370061e+10  \n",
       "Raíz del Error Cuadrado Promedio  2.523898e+05  \n",
       "R2                               -1.534266e+00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ds3nare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ds3nare.to_csv('ds3nare.csv')\n",
    "ds3nare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41\n",
      "[LightGBM] [Info] Number of data points in the train set: 263, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 308288.973384\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = dseu['Calificacion_critica']\n",
    "y = dseu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.321537e+05</td>\n",
       "      <td>3.139624e+05</td>\n",
       "      <td>2.319469e+05</td>\n",
       "      <td>3.137674e+05</td>\n",
       "      <td>3.066866e+05</td>\n",
       "      <td>3.136593e+05</td>\n",
       "      <td>3.280708e+05</td>\n",
       "      <td>2.463537e+05</td>\n",
       "      <td>2.978635e+05</td>\n",
       "      <td>2.934713e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.421094e+11</td>\n",
       "      <td>2.269093e+11</td>\n",
       "      <td>3.182803e+11</td>\n",
       "      <td>2.899439e+11</td>\n",
       "      <td>2.803490e+11</td>\n",
       "      <td>2.898615e+11</td>\n",
       "      <td>3.582358e+11</td>\n",
       "      <td>3.317108e+11</td>\n",
       "      <td>2.747616e+11</td>\n",
       "      <td>2.306661e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>4.920462e+05</td>\n",
       "      <td>4.763500e+05</td>\n",
       "      <td>5.641634e+05</td>\n",
       "      <td>5.384644e+05</td>\n",
       "      <td>5.294799e+05</td>\n",
       "      <td>5.383879e+05</td>\n",
       "      <td>5.985280e+05</td>\n",
       "      <td>5.759434e+05</td>\n",
       "      <td>5.241770e+05</td>\n",
       "      <td>4.802772e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.068770e-01</td>\n",
       "      <td>1.629491e-01</td>\n",
       "      <td>-1.741114e-01</td>\n",
       "      <td>-6.958054e-02</td>\n",
       "      <td>-3.418564e-02</td>\n",
       "      <td>-6.927675e-02</td>\n",
       "      <td>-3.215043e-01</td>\n",
       "      <td>-2.236553e-01</td>\n",
       "      <td>-1.357415e-02</td>\n",
       "      <td>1.490904e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.321537e+05  3.139624e+05  2.319469e+05   \n",
       "Error Cuadrado Promedio           2.421094e+11  2.269093e+11  3.182803e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.920462e+05  4.763500e+05  5.641634e+05   \n",
       "R2                                1.068770e-01  1.629491e-01 -1.741114e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  3.137674e+05      3.066866e+05   \n",
       "Error Cuadrado Promedio                  2.899439e+11      2.803490e+11   \n",
       "Raíz del Error Cuadrado Promedio         5.384644e+05      5.294799e+05   \n",
       "R2                                      -6.958054e-02     -3.418564e-02   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           3.136593e+05         3.280708e+05   \n",
       "Error Cuadrado Promedio           2.898615e+11         3.582358e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.383879e+05         5.985280e+05   \n",
       "R2                               -6.927675e-02        -3.215043e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.463537e+05       2.978635e+05   \n",
       "Error Cuadrado Promedio                     3.317108e+11       2.747616e+11   \n",
       "Raíz del Error Cuadrado Promedio            5.759434e+05       5.241770e+05   \n",
       "R2                                         -2.236553e-01      -1.357415e-02   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.934713e+05  \n",
       "Error Cuadrado Promedio           2.306661e+11  \n",
       "Raíz del Error Cuadrado Promedio  4.802772e+05  \n",
       "R2                                1.490904e-01  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "dseure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "dseure.to_csv('dseure.csv')\n",
    "dseure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 32\n",
      "[LightGBM] [Info] Number of data points in the train set: 138, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 461811.594203\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = dsjp['Calificacion_critica']\n",
    "y = dsjp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>4.411646e+05</td>\n",
       "      <td>4.521052e+05</td>\n",
       "      <td>3.331656e+05</td>\n",
       "      <td>7.493004e+05</td>\n",
       "      <td>6.759810e+05</td>\n",
       "      <td>7.450177e+05</td>\n",
       "      <td>5.565333e+05</td>\n",
       "      <td>3.834730e+05</td>\n",
       "      <td>7.165459e+05</td>\n",
       "      <td>5.529246e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>5.237547e+11</td>\n",
       "      <td>5.254346e+11</td>\n",
       "      <td>6.105797e+11</td>\n",
       "      <td>1.778277e+12</td>\n",
       "      <td>1.419969e+12</td>\n",
       "      <td>1.776098e+12</td>\n",
       "      <td>8.277717e+11</td>\n",
       "      <td>6.907154e+11</td>\n",
       "      <td>1.607721e+12</td>\n",
       "      <td>7.059094e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>7.237090e+05</td>\n",
       "      <td>7.248686e+05</td>\n",
       "      <td>7.813960e+05</td>\n",
       "      <td>1.333521e+06</td>\n",
       "      <td>1.191624e+06</td>\n",
       "      <td>1.332703e+06</td>\n",
       "      <td>9.098196e+05</td>\n",
       "      <td>8.310929e+05</td>\n",
       "      <td>1.267959e+06</td>\n",
       "      <td>8.401841e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>3.663685e-02</td>\n",
       "      <td>3.354712e-02</td>\n",
       "      <td>-1.230637e-01</td>\n",
       "      <td>-2.270856e+00</td>\n",
       "      <td>-1.611806e+00</td>\n",
       "      <td>-2.266848e+00</td>\n",
       "      <td>-5.225538e-01</td>\n",
       "      <td>-2.704606e-01</td>\n",
       "      <td>-1.957146e+00</td>\n",
       "      <td>-2.984075e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           4.411646e+05  4.521052e+05  3.331656e+05   \n",
       "Error Cuadrado Promedio           5.237547e+11  5.254346e+11  6.105797e+11   \n",
       "Raíz del Error Cuadrado Promedio  7.237090e+05  7.248686e+05  7.813960e+05   \n",
       "R2                                3.663685e-02  3.354712e-02 -1.230637e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  7.493004e+05      6.759810e+05   \n",
       "Error Cuadrado Promedio                  1.778277e+12      1.419969e+12   \n",
       "Raíz del Error Cuadrado Promedio         1.333521e+06      1.191624e+06   \n",
       "R2                                      -2.270856e+00     -1.611806e+00   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           7.450177e+05         5.565333e+05   \n",
       "Error Cuadrado Promedio           1.776098e+12         8.277717e+11   \n",
       "Raíz del Error Cuadrado Promedio  1.332703e+06         9.098196e+05   \n",
       "R2                               -2.266848e+00        -5.225538e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     3.834730e+05       7.165459e+05   \n",
       "Error Cuadrado Promedio                     6.907154e+11       1.607721e+12   \n",
       "Raíz del Error Cuadrado Promedio            8.310929e+05       1.267959e+06   \n",
       "R2                                         -2.704606e-01      -1.957146e+00   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           5.529246e+05  \n",
       "Error Cuadrado Promedio           7.059094e+11  \n",
       "Raíz del Error Cuadrado Promedio  8.401841e+05  \n",
       "R2                               -2.984075e-01  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "dsjpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "dsjpre.to_csv('dsjpre.csv')\n",
    "dsjpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 491, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 286741.344196\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = dsna['Calificacion_critica']\n",
    "y = dsna['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.704317e+05</td>\n",
       "      <td>2.604397e+05</td>\n",
       "      <td>2.456278e+05</td>\n",
       "      <td>2.813123e+05</td>\n",
       "      <td>2.966311e+05</td>\n",
       "      <td>2.812756e+05</td>\n",
       "      <td>3.048152e+05</td>\n",
       "      <td>3.121887e+05</td>\n",
       "      <td>2.731330e+05</td>\n",
       "      <td>2.762939e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>6.477838e+11</td>\n",
       "      <td>6.188149e+11</td>\n",
       "      <td>7.268931e+11</td>\n",
       "      <td>7.010451e+11</td>\n",
       "      <td>7.275967e+11</td>\n",
       "      <td>7.010130e+11</td>\n",
       "      <td>5.762940e+11</td>\n",
       "      <td>7.824489e+11</td>\n",
       "      <td>6.907521e+11</td>\n",
       "      <td>6.296439e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>8.048502e+05</td>\n",
       "      <td>7.866479e+05</td>\n",
       "      <td>8.525802e+05</td>\n",
       "      <td>8.372843e+05</td>\n",
       "      <td>8.529928e+05</td>\n",
       "      <td>8.372652e+05</td>\n",
       "      <td>7.591403e+05</td>\n",
       "      <td>8.845614e+05</td>\n",
       "      <td>8.311150e+05</td>\n",
       "      <td>7.935010e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>5.456942e-02</td>\n",
       "      <td>9.684909e-02</td>\n",
       "      <td>-6.088928e-02</td>\n",
       "      <td>-2.316455e-02</td>\n",
       "      <td>-6.191626e-02</td>\n",
       "      <td>-2.311779e-02</td>\n",
       "      <td>1.589078e-01</td>\n",
       "      <td>-1.419721e-01</td>\n",
       "      <td>-8.142182e-03</td>\n",
       "      <td>8.104440e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.704317e+05  2.604397e+05  2.456278e+05   \n",
       "Error Cuadrado Promedio           6.477838e+11  6.188149e+11  7.268931e+11   \n",
       "Raíz del Error Cuadrado Promedio  8.048502e+05  7.866479e+05  8.525802e+05   \n",
       "R2                                5.456942e-02  9.684909e-02 -6.088928e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.813123e+05      2.966311e+05   \n",
       "Error Cuadrado Promedio                  7.010451e+11      7.275967e+11   \n",
       "Raíz del Error Cuadrado Promedio         8.372843e+05      8.529928e+05   \n",
       "R2                                      -2.316455e-02     -6.191626e-02   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.812756e+05         3.048152e+05   \n",
       "Error Cuadrado Promedio           7.010130e+11         5.762940e+11   \n",
       "Raíz del Error Cuadrado Promedio  8.372652e+05         7.591403e+05   \n",
       "R2                               -2.311779e-02         1.589078e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     3.121887e+05       2.731330e+05   \n",
       "Error Cuadrado Promedio                     7.824489e+11       6.907521e+11   \n",
       "Raíz del Error Cuadrado Promedio            8.845614e+05       8.311150e+05   \n",
       "R2                                         -1.419721e-01      -8.142182e-03   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.762939e+05  \n",
       "Error Cuadrado Promedio           6.296439e+11  \n",
       "Raíz del Error Cuadrado Promedio  7.935010e+05  \n",
       "R2                                8.104440e-02  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "dsnare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "dsnare.to_csv('dsnare.csv')\n",
    "dsnare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 48\n",
      "[LightGBM] [Info] Number of data points in the train set: 286, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 110419.580420\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = gbaeu['Calificacion_critica']\n",
    "y = gbaeu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>9.203264e+04</td>\n",
       "      <td>9.215748e+04</td>\n",
       "      <td>7.097617e+04</td>\n",
       "      <td>9.237258e+04</td>\n",
       "      <td>9.000709e+04</td>\n",
       "      <td>9.260621e+04</td>\n",
       "      <td>8.455285e+04</td>\n",
       "      <td>8.564139e+04</td>\n",
       "      <td>8.797164e+04</td>\n",
       "      <td>8.607536e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.745420e+10</td>\n",
       "      <td>1.728209e+10</td>\n",
       "      <td>1.944745e+10</td>\n",
       "      <td>1.963810e+10</td>\n",
       "      <td>1.834295e+10</td>\n",
       "      <td>1.961910e+10</td>\n",
       "      <td>1.784735e+10</td>\n",
       "      <td>2.539533e+10</td>\n",
       "      <td>1.722056e+10</td>\n",
       "      <td>1.647365e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.321143e+05</td>\n",
       "      <td>1.314614e+05</td>\n",
       "      <td>1.394541e+05</td>\n",
       "      <td>1.401360e+05</td>\n",
       "      <td>1.354361e+05</td>\n",
       "      <td>1.400682e+05</td>\n",
       "      <td>1.335940e+05</td>\n",
       "      <td>1.593591e+05</td>\n",
       "      <td>1.312271e+05</td>\n",
       "      <td>1.283497e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>3.458995e-02</td>\n",
       "      <td>4.410934e-02</td>\n",
       "      <td>-7.565908e-02</td>\n",
       "      <td>-8.620388e-02</td>\n",
       "      <td>-1.456769e-02</td>\n",
       "      <td>-8.515318e-02</td>\n",
       "      <td>1.284430e-02</td>\n",
       "      <td>-4.046424e-01</td>\n",
       "      <td>4.751251e-02</td>\n",
       "      <td>8.882534e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           9.203264e+04  9.215748e+04  7.097617e+04   \n",
       "Error Cuadrado Promedio           1.745420e+10  1.728209e+10  1.944745e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.321143e+05  1.314614e+05  1.394541e+05   \n",
       "R2                                3.458995e-02  4.410934e-02 -7.565908e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  9.237258e+04      9.000709e+04   \n",
       "Error Cuadrado Promedio                  1.963810e+10      1.834295e+10   \n",
       "Raíz del Error Cuadrado Promedio         1.401360e+05      1.354361e+05   \n",
       "R2                                      -8.620388e-02     -1.456769e-02   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           9.260621e+04         8.455285e+04   \n",
       "Error Cuadrado Promedio           1.961910e+10         1.784735e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.400682e+05         1.335940e+05   \n",
       "R2                               -8.515318e-02         1.284430e-02   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     8.564139e+04       8.797164e+04   \n",
       "Error Cuadrado Promedio                     2.539533e+10       1.722056e+10   \n",
       "Raíz del Error Cuadrado Promedio            1.593591e+05       1.312271e+05   \n",
       "R2                                         -4.046424e-01       4.751251e-02   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           8.607536e+04  \n",
       "Error Cuadrado Promedio           1.647365e+10  \n",
       "Raíz del Error Cuadrado Promedio  1.283497e+05  \n",
       "R2                                8.882534e-02  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "gbaeure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "gbaeure.to_csv('gbaeure.csv')\n",
    "gbaeure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14\n",
      "[LightGBM] [Info] Number of data points in the train set: 41, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 311951.219512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = gbajp['Calificacion_critica']\n",
    "y = gbajp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>1.903514e+05</td>\n",
       "      <td>1.900577e+05</td>\n",
       "      <td>1.294419e+05</td>\n",
       "      <td>2.350926e+05</td>\n",
       "      <td>2.200801e+05</td>\n",
       "      <td>2.350840e+05</td>\n",
       "      <td>1.800000e+05</td>\n",
       "      <td>2.357066e+05</td>\n",
       "      <td>2.272673e+05</td>\n",
       "      <td>1.875984e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>5.027667e+10</td>\n",
       "      <td>5.279515e+10</td>\n",
       "      <td>4.708212e+10</td>\n",
       "      <td>9.229213e+10</td>\n",
       "      <td>8.321792e+10</td>\n",
       "      <td>9.228829e+10</td>\n",
       "      <td>6.021067e+10</td>\n",
       "      <td>9.826284e+10</td>\n",
       "      <td>8.898757e+10</td>\n",
       "      <td>5.469178e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>2.242246e+05</td>\n",
       "      <td>2.297719e+05</td>\n",
       "      <td>2.169842e+05</td>\n",
       "      <td>3.037962e+05</td>\n",
       "      <td>2.884752e+05</td>\n",
       "      <td>3.037899e+05</td>\n",
       "      <td>2.453786e+05</td>\n",
       "      <td>3.134690e+05</td>\n",
       "      <td>2.983079e+05</td>\n",
       "      <td>2.338627e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-1.770907e-01</td>\n",
       "      <td>-2.360540e-01</td>\n",
       "      <td>-1.022991e-01</td>\n",
       "      <td>-1.160768e+00</td>\n",
       "      <td>-9.483201e-01</td>\n",
       "      <td>-1.160678e+00</td>\n",
       "      <td>-4.096681e-01</td>\n",
       "      <td>-1.300556e+00</td>\n",
       "      <td>-1.083401e+00</td>\n",
       "      <td>-2.804584e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           1.903514e+05  1.900577e+05  1.294419e+05   \n",
       "Error Cuadrado Promedio           5.027667e+10  5.279515e+10  4.708212e+10   \n",
       "Raíz del Error Cuadrado Promedio  2.242246e+05  2.297719e+05  2.169842e+05   \n",
       "R2                               -1.770907e-01 -2.360540e-01 -1.022991e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.350926e+05      2.200801e+05   \n",
       "Error Cuadrado Promedio                  9.229213e+10      8.321792e+10   \n",
       "Raíz del Error Cuadrado Promedio         3.037962e+05      2.884752e+05   \n",
       "R2                                      -1.160768e+00     -9.483201e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.350840e+05         1.800000e+05   \n",
       "Error Cuadrado Promedio           9.228829e+10         6.021067e+10   \n",
       "Raíz del Error Cuadrado Promedio  3.037899e+05         2.453786e+05   \n",
       "R2                               -1.160678e+00        -4.096681e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.357066e+05       2.272673e+05   \n",
       "Error Cuadrado Promedio                     9.826284e+10       8.898757e+10   \n",
       "Raíz del Error Cuadrado Promedio            3.134690e+05       2.983079e+05   \n",
       "R2                                         -1.300556e+00      -1.083401e+00   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           1.875984e+05  \n",
       "Error Cuadrado Promedio           5.469178e+10  \n",
       "Raíz del Error Cuadrado Promedio  2.338627e+05  \n",
       "R2                               -2.804584e-01  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "gbajpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "gbajpre.to_csv('gbajpre.csv')\n",
    "gbajpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46\n",
      "[LightGBM] [Info] Number of data points in the train set: 303, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 253729.372937\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = gbana['Calificacion_critica']\n",
    "y = gbana['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.152663e+05</td>\n",
       "      <td>2.064703e+05</td>\n",
       "      <td>1.818314e+05</td>\n",
       "      <td>2.067673e+05</td>\n",
       "      <td>1.993068e+05</td>\n",
       "      <td>2.066088e+05</td>\n",
       "      <td>2.094962e+05</td>\n",
       "      <td>2.254738e+05</td>\n",
       "      <td>2.005008e+05</td>\n",
       "      <td>2.040387e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.112544e+11</td>\n",
       "      <td>1.066386e+11</td>\n",
       "      <td>1.322281e+11</td>\n",
       "      <td>1.196339e+11</td>\n",
       "      <td>1.086064e+11</td>\n",
       "      <td>1.195972e+11</td>\n",
       "      <td>1.255729e+11</td>\n",
       "      <td>1.716270e+11</td>\n",
       "      <td>1.123123e+11</td>\n",
       "      <td>1.128650e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>3.335482e+05</td>\n",
       "      <td>3.265556e+05</td>\n",
       "      <td>3.636318e+05</td>\n",
       "      <td>3.458814e+05</td>\n",
       "      <td>3.295548e+05</td>\n",
       "      <td>3.458283e+05</td>\n",
       "      <td>3.543626e+05</td>\n",
       "      <td>4.142789e+05</td>\n",
       "      <td>3.351303e+05</td>\n",
       "      <td>3.359538e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>7.932755e-02</td>\n",
       "      <td>1.175251e-01</td>\n",
       "      <td>-9.423796e-02</td>\n",
       "      <td>9.983875e-03</td>\n",
       "      <td>1.012410e-01</td>\n",
       "      <td>1.028775e-02</td>\n",
       "      <td>-3.916336e-02</td>\n",
       "      <td>-4.202785e-01</td>\n",
       "      <td>7.057293e-02</td>\n",
       "      <td>6.599951e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.152663e+05  2.064703e+05  1.818314e+05   \n",
       "Error Cuadrado Promedio           1.112544e+11  1.066386e+11  1.322281e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.335482e+05  3.265556e+05  3.636318e+05   \n",
       "R2                                7.932755e-02  1.175251e-01 -9.423796e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.067673e+05      1.993068e+05   \n",
       "Error Cuadrado Promedio                  1.196339e+11      1.086064e+11   \n",
       "Raíz del Error Cuadrado Promedio         3.458814e+05      3.295548e+05   \n",
       "R2                                       9.983875e-03      1.012410e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.066088e+05         2.094962e+05   \n",
       "Error Cuadrado Promedio           1.195972e+11         1.255729e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.458283e+05         3.543626e+05   \n",
       "R2                                1.028775e-02        -3.916336e-02   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.254738e+05       2.005008e+05   \n",
       "Error Cuadrado Promedio                     1.716270e+11       1.123123e+11   \n",
       "Raíz del Error Cuadrado Promedio            4.142789e+05       3.351303e+05   \n",
       "R2                                         -4.202785e-01       7.057293e-02   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.040387e+05  \n",
       "Error Cuadrado Promedio           1.128650e+11  \n",
       "Raíz del Error Cuadrado Promedio  3.359538e+05  \n",
       "R2                                6.599951e-02  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "gbanare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "gbanare.to_csv('gbanare.csv')\n",
    "gbanare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 44\n",
      "[LightGBM] [Info] Number of data points in the train set: 289, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 84186.851211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = gceu['Calificacion_critica']\n",
    "y = gceu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>6.913882e+04</td>\n",
       "      <td>6.375329e+04</td>\n",
       "      <td>5.519504e+04</td>\n",
       "      <td>5.892650e+04</td>\n",
       "      <td>5.841275e+04</td>\n",
       "      <td>5.884537e+04</td>\n",
       "      <td>5.926400e+04</td>\n",
       "      <td>7.026758e+04</td>\n",
       "      <td>5.684654e+04</td>\n",
       "      <td>5.753183e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.149072e+10</td>\n",
       "      <td>1.097354e+10</td>\n",
       "      <td>1.352432e+10</td>\n",
       "      <td>9.726062e+09</td>\n",
       "      <td>9.537116e+09</td>\n",
       "      <td>9.724738e+09</td>\n",
       "      <td>1.047443e+10</td>\n",
       "      <td>1.745156e+10</td>\n",
       "      <td>9.172054e+09</td>\n",
       "      <td>1.009388e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.071948e+05</td>\n",
       "      <td>1.047547e+05</td>\n",
       "      <td>1.162941e+05</td>\n",
       "      <td>9.862080e+04</td>\n",
       "      <td>9.765816e+04</td>\n",
       "      <td>9.861409e+04</td>\n",
       "      <td>1.023447e+05</td>\n",
       "      <td>1.321044e+05</td>\n",
       "      <td>9.577084e+04</td>\n",
       "      <td>1.004683e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>8.303784e-02</td>\n",
       "      <td>1.243090e-01</td>\n",
       "      <td>-7.924424e-02</td>\n",
       "      <td>2.238579e-01</td>\n",
       "      <td>2.389358e-01</td>\n",
       "      <td>2.239635e-01</td>\n",
       "      <td>1.641377e-01</td>\n",
       "      <td>-3.926392e-01</td>\n",
       "      <td>2.680679e-01</td>\n",
       "      <td>1.945062e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           6.913882e+04  6.375329e+04  5.519504e+04   \n",
       "Error Cuadrado Promedio           1.149072e+10  1.097354e+10  1.352432e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.071948e+05  1.047547e+05  1.162941e+05   \n",
       "R2                                8.303784e-02  1.243090e-01 -7.924424e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  5.892650e+04      5.841275e+04   \n",
       "Error Cuadrado Promedio                  9.726062e+09      9.537116e+09   \n",
       "Raíz del Error Cuadrado Promedio         9.862080e+04      9.765816e+04   \n",
       "R2                                       2.238579e-01      2.389358e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           5.884537e+04         5.926400e+04   \n",
       "Error Cuadrado Promedio           9.724738e+09         1.047443e+10   \n",
       "Raíz del Error Cuadrado Promedio  9.861409e+04         1.023447e+05   \n",
       "R2                                2.239635e-01         1.641377e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     7.026758e+04       5.684654e+04   \n",
       "Error Cuadrado Promedio                     1.745156e+10       9.172054e+09   \n",
       "Raíz del Error Cuadrado Promedio            1.321044e+05       9.577084e+04   \n",
       "R2                                         -3.926392e-01       2.680679e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           5.753183e+04  \n",
       "Error Cuadrado Promedio           1.009388e+10  \n",
       "Raíz del Error Cuadrado Promedio  1.004683e+05  \n",
       "R2                                1.945062e-01  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "gceure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "gceure.to_csv('gceure.csv')\n",
    "gceure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 41, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 272926.829268\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = gcjp['Calificacion_critica']\n",
    "y = gcjp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.169934e+05</td>\n",
       "      <td>2.178417e+05</td>\n",
       "      <td>2.138885e+05</td>\n",
       "      <td>3.369444e+05</td>\n",
       "      <td>3.171276e+05</td>\n",
       "      <td>3.369444e+05</td>\n",
       "      <td>2.985556e+05</td>\n",
       "      <td>2.735472e+05</td>\n",
       "      <td>3.319023e+05</td>\n",
       "      <td>2.323171e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>6.216206e+10</td>\n",
       "      <td>6.529637e+10</td>\n",
       "      <td>9.271644e+10</td>\n",
       "      <td>1.893853e+11</td>\n",
       "      <td>1.474624e+11</td>\n",
       "      <td>1.893835e+11</td>\n",
       "      <td>1.155073e+11</td>\n",
       "      <td>1.438542e+11</td>\n",
       "      <td>1.807844e+11</td>\n",
       "      <td>6.903580e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>2.493232e+05</td>\n",
       "      <td>2.555316e+05</td>\n",
       "      <td>3.044937e+05</td>\n",
       "      <td>4.351843e+05</td>\n",
       "      <td>3.840083e+05</td>\n",
       "      <td>4.351821e+05</td>\n",
       "      <td>3.398637e+05</td>\n",
       "      <td>3.792812e+05</td>\n",
       "      <td>4.251875e+05</td>\n",
       "      <td>2.627467e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>9.955572e-02</td>\n",
       "      <td>5.415383e-02</td>\n",
       "      <td>-3.430377e-01</td>\n",
       "      <td>-1.743328e+00</td>\n",
       "      <td>-1.136057e+00</td>\n",
       "      <td>-1.743301e+00</td>\n",
       "      <td>-6.731736e-01</td>\n",
       "      <td>-1.083790e+00</td>\n",
       "      <td>-1.618740e+00</td>\n",
       "      <td>-1.340712e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.169934e+05  2.178417e+05  2.138885e+05   \n",
       "Error Cuadrado Promedio           6.216206e+10  6.529637e+10  9.271644e+10   \n",
       "Raíz del Error Cuadrado Promedio  2.493232e+05  2.555316e+05  3.044937e+05   \n",
       "R2                                9.955572e-02  5.415383e-02 -3.430377e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  3.369444e+05      3.171276e+05   \n",
       "Error Cuadrado Promedio                  1.893853e+11      1.474624e+11   \n",
       "Raíz del Error Cuadrado Promedio         4.351843e+05      3.840083e+05   \n",
       "R2                                      -1.743328e+00     -1.136057e+00   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           3.369444e+05         2.985556e+05   \n",
       "Error Cuadrado Promedio           1.893835e+11         1.155073e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.351821e+05         3.398637e+05   \n",
       "R2                               -1.743301e+00        -6.731736e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.735472e+05       3.319023e+05   \n",
       "Error Cuadrado Promedio                     1.438542e+11       1.807844e+11   \n",
       "Raíz del Error Cuadrado Promedio            3.792812e+05       4.251875e+05   \n",
       "R2                                         -1.083790e+00      -1.618740e+00   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.323171e+05  \n",
       "Error Cuadrado Promedio           6.903580e+10  \n",
       "Raíz del Error Cuadrado Promedio  2.627467e+05  \n",
       "R2                               -1.340712e-05  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "gcjpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "gcjpre.to_csv('gcjpre.csv')\n",
    "gcjpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 49\n",
      "[LightGBM] [Info] Number of data points in the train set: 312, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 268365.384615\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = gcna['Calificacion_critica']\n",
    "y = gcna['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.287687e+05</td>\n",
       "      <td>2.126900e+05</td>\n",
       "      <td>1.905104e+05</td>\n",
       "      <td>2.185520e+05</td>\n",
       "      <td>2.177174e+05</td>\n",
       "      <td>2.180436e+05</td>\n",
       "      <td>2.239111e+05</td>\n",
       "      <td>2.465172e+05</td>\n",
       "      <td>2.105873e+05</td>\n",
       "      <td>2.198748e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.142324e+11</td>\n",
       "      <td>1.102087e+11</td>\n",
       "      <td>1.363734e+11</td>\n",
       "      <td>1.070734e+11</td>\n",
       "      <td>1.071719e+11</td>\n",
       "      <td>1.070270e+11</td>\n",
       "      <td>1.173481e+11</td>\n",
       "      <td>1.832614e+11</td>\n",
       "      <td>1.043022e+11</td>\n",
       "      <td>1.175491e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>3.379829e+05</td>\n",
       "      <td>3.319769e+05</td>\n",
       "      <td>3.692876e+05</td>\n",
       "      <td>3.272207e+05</td>\n",
       "      <td>3.273713e+05</td>\n",
       "      <td>3.271498e+05</td>\n",
       "      <td>3.425612e+05</td>\n",
       "      <td>4.280904e+05</td>\n",
       "      <td>3.229586e+05</td>\n",
       "      <td>3.428543e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>6.775773e-02</td>\n",
       "      <td>1.005954e-01</td>\n",
       "      <td>-1.129328e-01</td>\n",
       "      <td>1.261820e-01</td>\n",
       "      <td>1.253777e-01</td>\n",
       "      <td>1.265607e-01</td>\n",
       "      <td>4.233051e-02</td>\n",
       "      <td>-4.955829e-01</td>\n",
       "      <td>1.487972e-01</td>\n",
       "      <td>4.069063e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.287687e+05  2.126900e+05  1.905104e+05   \n",
       "Error Cuadrado Promedio           1.142324e+11  1.102087e+11  1.363734e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.379829e+05  3.319769e+05  3.692876e+05   \n",
       "R2                                6.775773e-02  1.005954e-01 -1.129328e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.185520e+05      2.177174e+05   \n",
       "Error Cuadrado Promedio                  1.070734e+11      1.071719e+11   \n",
       "Raíz del Error Cuadrado Promedio         3.272207e+05      3.273713e+05   \n",
       "R2                                       1.261820e-01      1.253777e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.180436e+05         2.239111e+05   \n",
       "Error Cuadrado Promedio           1.070270e+11         1.173481e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.271498e+05         3.425612e+05   \n",
       "R2                                1.265607e-01         4.233051e-02   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.465172e+05       2.105873e+05   \n",
       "Error Cuadrado Promedio                     1.832614e+11       1.043022e+11   \n",
       "Raíz del Error Cuadrado Promedio            4.280904e+05       3.229586e+05   \n",
       "R2                                         -4.955829e-01       1.487972e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.198748e+05  \n",
       "Error Cuadrado Promedio           1.175491e+11  \n",
       "Raíz del Error Cuadrado Promedio  3.428543e+05  \n",
       "R2                                4.069063e-02  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "gcnare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "gcnare.to_csv('gcnare.csv')\n",
    "gcnare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 47\n",
      "[LightGBM] [Info] Number of data points in the train set: 476, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 158340.336134\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = pceu['Calificacion_critica']\n",
    "y = pceu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>1.905758e+05</td>\n",
       "      <td>1.796114e+05</td>\n",
       "      <td>1.524987e+05</td>\n",
       "      <td>1.866249e+05</td>\n",
       "      <td>1.863654e+05</td>\n",
       "      <td>1.866239e+05</td>\n",
       "      <td>1.815686e+05</td>\n",
       "      <td>1.702584e+05</td>\n",
       "      <td>1.849685e+05</td>\n",
       "      <td>1.860299e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.482461e+11</td>\n",
       "      <td>2.434261e+11</td>\n",
       "      <td>2.762859e+11</td>\n",
       "      <td>2.498802e+11</td>\n",
       "      <td>2.493829e+11</td>\n",
       "      <td>2.498790e+11</td>\n",
       "      <td>2.592084e+11</td>\n",
       "      <td>2.874923e+11</td>\n",
       "      <td>2.488359e+11</td>\n",
       "      <td>2.491695e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>4.982430e+05</td>\n",
       "      <td>4.933823e+05</td>\n",
       "      <td>5.256291e+05</td>\n",
       "      <td>4.998802e+05</td>\n",
       "      <td>4.993826e+05</td>\n",
       "      <td>4.998789e+05</td>\n",
       "      <td>5.091252e+05</td>\n",
       "      <td>5.361831e+05</td>\n",
       "      <td>4.988346e+05</td>\n",
       "      <td>4.991688e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>4.000108e-02</td>\n",
       "      <td>5.864065e-02</td>\n",
       "      <td>-6.843247e-02</td>\n",
       "      <td>3.368166e-02</td>\n",
       "      <td>3.560472e-02</td>\n",
       "      <td>3.368661e-02</td>\n",
       "      <td>-2.391658e-03</td>\n",
       "      <td>-1.117689e-01</td>\n",
       "      <td>3.772018e-02</td>\n",
       "      <td>3.643019e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           1.905758e+05  1.796114e+05  1.524987e+05   \n",
       "Error Cuadrado Promedio           2.482461e+11  2.434261e+11  2.762859e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.982430e+05  4.933823e+05  5.256291e+05   \n",
       "R2                                4.000108e-02  5.864065e-02 -6.843247e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  1.866249e+05      1.863654e+05   \n",
       "Error Cuadrado Promedio                  2.498802e+11      2.493829e+11   \n",
       "Raíz del Error Cuadrado Promedio         4.998802e+05      4.993826e+05   \n",
       "R2                                       3.368166e-02      3.560472e-02   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           1.866239e+05         1.815686e+05   \n",
       "Error Cuadrado Promedio           2.498790e+11         2.592084e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.998789e+05         5.091252e+05   \n",
       "R2                                3.368661e-02        -2.391658e-03   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     1.702584e+05       1.849685e+05   \n",
       "Error Cuadrado Promedio                     2.874923e+11       2.488359e+11   \n",
       "Raíz del Error Cuadrado Promedio            5.361831e+05       4.988346e+05   \n",
       "R2                                         -1.117689e-01       3.772018e-02   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           1.860299e+05  \n",
       "Error Cuadrado Promedio           2.491695e+11  \n",
       "Raíz del Error Cuadrado Promedio  4.991688e+05  \n",
       "R2                                3.643019e-02  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "pceure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "pceure.to_csv('pceure.csv')\n",
    "pceure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37\n",
      "[LightGBM] [Info] Number of data points in the train set: 215, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 203116.279070\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = pcna['Calificacion_critica']\n",
    "y = pcna['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.836816e+05</td>\n",
       "      <td>2.745935e+05</td>\n",
       "      <td>2.288170e+05</td>\n",
       "      <td>2.930723e+05</td>\n",
       "      <td>2.924617e+05</td>\n",
       "      <td>2.930708e+05</td>\n",
       "      <td>2.698925e+05</td>\n",
       "      <td>2.455289e+05</td>\n",
       "      <td>2.884269e+05</td>\n",
       "      <td>2.889533e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>3.115918e+11</td>\n",
       "      <td>3.024067e+11</td>\n",
       "      <td>3.697348e+11</td>\n",
       "      <td>2.891294e+11</td>\n",
       "      <td>2.892327e+11</td>\n",
       "      <td>2.891285e+11</td>\n",
       "      <td>3.143921e+11</td>\n",
       "      <td>3.913458e+11</td>\n",
       "      <td>2.854046e+11</td>\n",
       "      <td>3.143510e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>5.582041e+05</td>\n",
       "      <td>5.499152e+05</td>\n",
       "      <td>6.080582e+05</td>\n",
       "      <td>5.377076e+05</td>\n",
       "      <td>5.378036e+05</td>\n",
       "      <td>5.377067e+05</td>\n",
       "      <td>5.607068e+05</td>\n",
       "      <td>6.255764e+05</td>\n",
       "      <td>5.342327e+05</td>\n",
       "      <td>5.606702e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>5.892535e-02</td>\n",
       "      <td>8.666642e-02</td>\n",
       "      <td>-1.166788e-01</td>\n",
       "      <td>1.267667e-01</td>\n",
       "      <td>1.264549e-01</td>\n",
       "      <td>1.267695e-01</td>\n",
       "      <td>5.046797e-02</td>\n",
       "      <td>-1.819490e-01</td>\n",
       "      <td>1.380164e-01</td>\n",
       "      <td>5.059197e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.836816e+05  2.745935e+05  2.288170e+05   \n",
       "Error Cuadrado Promedio           3.115918e+11  3.024067e+11  3.697348e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.582041e+05  5.499152e+05  6.080582e+05   \n",
       "R2                                5.892535e-02  8.666642e-02 -1.166788e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.930723e+05      2.924617e+05   \n",
       "Error Cuadrado Promedio                  2.891294e+11      2.892327e+11   \n",
       "Raíz del Error Cuadrado Promedio         5.377076e+05      5.378036e+05   \n",
       "R2                                       1.267667e-01      1.264549e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.930708e+05         2.698925e+05   \n",
       "Error Cuadrado Promedio           2.891285e+11         3.143921e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.377067e+05         5.607068e+05   \n",
       "R2                                1.267695e-01         5.046797e-02   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.455289e+05       2.884269e+05   \n",
       "Error Cuadrado Promedio                     3.913458e+11       2.854046e+11   \n",
       "Raíz del Error Cuadrado Promedio            6.255764e+05       5.342327e+05   \n",
       "R2                                         -1.819490e-01       1.380164e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.889533e+05  \n",
       "Error Cuadrado Promedio           3.143510e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.606702e+05  \n",
       "R2                                5.059197e-02  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "pcnare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "pcnare.to_csv('pcnare.csv')\n",
    "pcnare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 62\n",
      "[LightGBM] [Info] Number of data points in the train set: 879, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 220420.932878\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ps2eu['Calificacion_critica']\n",
    "y = ps2eu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.095429e+05</td>\n",
       "      <td>1.947426e+05</td>\n",
       "      <td>1.718728e+05</td>\n",
       "      <td>1.946675e+05</td>\n",
       "      <td>1.959816e+05</td>\n",
       "      <td>1.946637e+05</td>\n",
       "      <td>2.253687e+05</td>\n",
       "      <td>2.040903e+05</td>\n",
       "      <td>1.918477e+05</td>\n",
       "      <td>1.989901e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.252739e+11</td>\n",
       "      <td>1.189305e+11</td>\n",
       "      <td>1.549336e+11</td>\n",
       "      <td>1.331230e+11</td>\n",
       "      <td>1.347757e+11</td>\n",
       "      <td>1.331193e+11</td>\n",
       "      <td>1.589782e+11</td>\n",
       "      <td>1.792319e+11</td>\n",
       "      <td>1.306358e+11</td>\n",
       "      <td>1.343771e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>3.539406e+05</td>\n",
       "      <td>3.448630e+05</td>\n",
       "      <td>3.936161e+05</td>\n",
       "      <td>3.648602e+05</td>\n",
       "      <td>3.671181e+05</td>\n",
       "      <td>3.648552e+05</td>\n",
       "      <td>3.987207e+05</td>\n",
       "      <td>4.233579e+05</td>\n",
       "      <td>3.614357e+05</td>\n",
       "      <td>3.665749e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>9.128654e-02</td>\n",
       "      <td>1.373006e-01</td>\n",
       "      <td>-1.238592e-01</td>\n",
       "      <td>3.435085e-02</td>\n",
       "      <td>2.236262e-02</td>\n",
       "      <td>3.437759e-02</td>\n",
       "      <td>-1.531978e-01</td>\n",
       "      <td>-3.001143e-01</td>\n",
       "      <td>5.239270e-02</td>\n",
       "      <td>2.525365e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.095429e+05  1.947426e+05  1.718728e+05   \n",
       "Error Cuadrado Promedio           1.252739e+11  1.189305e+11  1.549336e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.539406e+05  3.448630e+05  3.936161e+05   \n",
       "R2                                9.128654e-02  1.373006e-01 -1.238592e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  1.946675e+05      1.959816e+05   \n",
       "Error Cuadrado Promedio                  1.331230e+11      1.347757e+11   \n",
       "Raíz del Error Cuadrado Promedio         3.648602e+05      3.671181e+05   \n",
       "R2                                       3.435085e-02      2.236262e-02   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           1.946637e+05         2.253687e+05   \n",
       "Error Cuadrado Promedio           1.331193e+11         1.589782e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.648552e+05         3.987207e+05   \n",
       "R2                                3.437759e-02        -1.531978e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.040903e+05       1.918477e+05   \n",
       "Error Cuadrado Promedio                     1.792319e+11       1.306358e+11   \n",
       "Raíz del Error Cuadrado Promedio            4.233579e+05       3.614357e+05   \n",
       "R2                                         -3.001143e-01       5.239270e-02   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           1.989901e+05  \n",
       "Error Cuadrado Promedio           1.343771e+11  \n",
       "Raíz del Error Cuadrado Promedio  3.665749e+05  \n",
       "R2                                2.525365e-02  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ps2eure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ps2eure.to_csv('ps2eure.csv')\n",
    "ps2eure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 38\n",
      "[LightGBM] [Info] Number of data points in the train set: 199, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 261859.296482\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ps2jp['Calificacion_critica']\n",
    "y = ps2jp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.668213e+05</td>\n",
       "      <td>2.673631e+05</td>\n",
       "      <td>2.461631e+05</td>\n",
       "      <td>2.917830e+05</td>\n",
       "      <td>2.887223e+05</td>\n",
       "      <td>2.839020e+05</td>\n",
       "      <td>2.912093e+05</td>\n",
       "      <td>2.900549e+05</td>\n",
       "      <td>2.803990e+05</td>\n",
       "      <td>2.729069e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.922349e+11</td>\n",
       "      <td>1.879850e+11</td>\n",
       "      <td>2.271040e+11</td>\n",
       "      <td>2.130721e+11</td>\n",
       "      <td>2.103599e+11</td>\n",
       "      <td>2.095145e+11</td>\n",
       "      <td>2.049033e+11</td>\n",
       "      <td>2.886227e+11</td>\n",
       "      <td>2.062788e+11</td>\n",
       "      <td>1.908789e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>4.384460e+05</td>\n",
       "      <td>4.335724e+05</td>\n",
       "      <td>4.765543e+05</td>\n",
       "      <td>4.615973e+05</td>\n",
       "      <td>4.586500e+05</td>\n",
       "      <td>4.577276e+05</td>\n",
       "      <td>4.526625e+05</td>\n",
       "      <td>5.372362e+05</td>\n",
       "      <td>4.541793e+05</td>\n",
       "      <td>4.368969e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>5.998091e-02</td>\n",
       "      <td>8.076261e-02</td>\n",
       "      <td>-1.105272e-01</td>\n",
       "      <td>-4.191207e-02</td>\n",
       "      <td>-2.864933e-02</td>\n",
       "      <td>-2.451574e-02</td>\n",
       "      <td>-1.967265e-03</td>\n",
       "      <td>-4.113507e-01</td>\n",
       "      <td>-8.693173e-03</td>\n",
       "      <td>6.661141e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.668213e+05  2.673631e+05  2.461631e+05   \n",
       "Error Cuadrado Promedio           1.922349e+11  1.879850e+11  2.271040e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.384460e+05  4.335724e+05  4.765543e+05   \n",
       "R2                                5.998091e-02  8.076261e-02 -1.105272e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.917830e+05      2.887223e+05   \n",
       "Error Cuadrado Promedio                  2.130721e+11      2.103599e+11   \n",
       "Raíz del Error Cuadrado Promedio         4.615973e+05      4.586500e+05   \n",
       "R2                                      -4.191207e-02     -2.864933e-02   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.839020e+05         2.912093e+05   \n",
       "Error Cuadrado Promedio           2.095145e+11         2.049033e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.577276e+05         4.526625e+05   \n",
       "R2                               -2.451574e-02        -1.967265e-03   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.900549e+05       2.803990e+05   \n",
       "Error Cuadrado Promedio                     2.886227e+11       2.062788e+11   \n",
       "Raíz del Error Cuadrado Promedio            5.372362e+05       4.541793e+05   \n",
       "R2                                         -4.113507e-01      -8.693173e-03   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.729069e+05  \n",
       "Error Cuadrado Promedio           1.908789e+11  \n",
       "Raíz del Error Cuadrado Promedio  4.368969e+05  \n",
       "R2                                6.661141e-02  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ps2jpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ps2jpre.to_csv('ps2jpre.csv')\n",
    "ps2jpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 61\n",
      "[LightGBM] [Info] Number of data points in the train set: 896, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 395625.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ps2na['Calificacion_critica']\n",
    "y = ps2na['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.443717e+05</td>\n",
       "      <td>3.109080e+05</td>\n",
       "      <td>3.079145e+05</td>\n",
       "      <td>2.923048e+05</td>\n",
       "      <td>2.940318e+05</td>\n",
       "      <td>2.922892e+05</td>\n",
       "      <td>3.351302e+05</td>\n",
       "      <td>3.643233e+05</td>\n",
       "      <td>2.874701e+05</td>\n",
       "      <td>2.992168e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.639839e+11</td>\n",
       "      <td>2.513986e+11</td>\n",
       "      <td>3.695462e+11</td>\n",
       "      <td>2.370902e+11</td>\n",
       "      <td>2.397508e+11</td>\n",
       "      <td>2.370817e+11</td>\n",
       "      <td>3.053596e+11</td>\n",
       "      <td>4.522924e+11</td>\n",
       "      <td>2.344400e+11</td>\n",
       "      <td>2.587780e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>5.137937e+05</td>\n",
       "      <td>5.013966e+05</td>\n",
       "      <td>6.079031e+05</td>\n",
       "      <td>4.869191e+05</td>\n",
       "      <td>4.896435e+05</td>\n",
       "      <td>4.869104e+05</td>\n",
       "      <td>5.525936e+05</td>\n",
       "      <td>6.725269e+05</td>\n",
       "      <td>4.841900e+05</td>\n",
       "      <td>5.087023e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.756859e-01</td>\n",
       "      <td>2.149849e-01</td>\n",
       "      <td>-1.539419e-01</td>\n",
       "      <td>2.596639e-01</td>\n",
       "      <td>2.513561e-01</td>\n",
       "      <td>2.596905e-01</td>\n",
       "      <td>4.648642e-02</td>\n",
       "      <td>-4.123246e-01</td>\n",
       "      <td>2.679396e-01</td>\n",
       "      <td>1.919418e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.443717e+05  3.109080e+05  3.079145e+05   \n",
       "Error Cuadrado Promedio           2.639839e+11  2.513986e+11  3.695462e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.137937e+05  5.013966e+05  6.079031e+05   \n",
       "R2                                1.756859e-01  2.149849e-01 -1.539419e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.923048e+05      2.940318e+05   \n",
       "Error Cuadrado Promedio                  2.370902e+11      2.397508e+11   \n",
       "Raíz del Error Cuadrado Promedio         4.869191e+05      4.896435e+05   \n",
       "R2                                       2.596639e-01      2.513561e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.922892e+05         3.351302e+05   \n",
       "Error Cuadrado Promedio           2.370817e+11         3.053596e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.869104e+05         5.525936e+05   \n",
       "R2                                2.596905e-01         4.648642e-02   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     3.643233e+05       2.874701e+05   \n",
       "Error Cuadrado Promedio                     4.522924e+11       2.344400e+11   \n",
       "Raíz del Error Cuadrado Promedio            6.725269e+05       4.841900e+05   \n",
       "R2                                         -4.123246e-01       2.679396e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.992168e+05  \n",
       "Error Cuadrado Promedio           2.587780e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.087023e+05  \n",
       "R2                                1.919418e-01  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ps2nare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ps2nare.to_csv('ps2nare.csv')\n",
    "ps2nare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 501, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 377305.389222\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ps3eu['Calificacion_critica']\n",
    "y = ps3eu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.468054e+05</td>\n",
       "      <td>3.040217e+05</td>\n",
       "      <td>3.315905e+05</td>\n",
       "      <td>3.161438e+05</td>\n",
       "      <td>3.140440e+05</td>\n",
       "      <td>3.155838e+05</td>\n",
       "      <td>3.146481e+05</td>\n",
       "      <td>4.082685e+05</td>\n",
       "      <td>3.109034e+05</td>\n",
       "      <td>3.181908e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>5.559261e+11</td>\n",
       "      <td>4.866817e+11</td>\n",
       "      <td>7.138529e+11</td>\n",
       "      <td>4.512204e+11</td>\n",
       "      <td>4.482844e+11</td>\n",
       "      <td>4.511499e+11</td>\n",
       "      <td>4.604945e+11</td>\n",
       "      <td>8.267968e+11</td>\n",
       "      <td>4.464652e+11</td>\n",
       "      <td>5.062102e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>7.456045e+05</td>\n",
       "      <td>6.976258e+05</td>\n",
       "      <td>8.448982e+05</td>\n",
       "      <td>6.717294e+05</td>\n",
       "      <td>6.695404e+05</td>\n",
       "      <td>6.716769e+05</td>\n",
       "      <td>6.785975e+05</td>\n",
       "      <td>9.092837e+05</td>\n",
       "      <td>6.681805e+05</td>\n",
       "      <td>7.114845e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.582903e-01</td>\n",
       "      <td>2.631309e-01</td>\n",
       "      <td>-8.082156e-02</td>\n",
       "      <td>3.168219e-01</td>\n",
       "      <td>3.212671e-01</td>\n",
       "      <td>3.169286e-01</td>\n",
       "      <td>3.027802e-01</td>\n",
       "      <td>-2.518262e-01</td>\n",
       "      <td>3.240215e-01</td>\n",
       "      <td>2.335634e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.468054e+05  3.040217e+05  3.315905e+05   \n",
       "Error Cuadrado Promedio           5.559261e+11  4.866817e+11  7.138529e+11   \n",
       "Raíz del Error Cuadrado Promedio  7.456045e+05  6.976258e+05  8.448982e+05   \n",
       "R2                                1.582903e-01  2.631309e-01 -8.082156e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  3.161438e+05      3.140440e+05   \n",
       "Error Cuadrado Promedio                  4.512204e+11      4.482844e+11   \n",
       "Raíz del Error Cuadrado Promedio         6.717294e+05      6.695404e+05   \n",
       "R2                                       3.168219e-01      3.212671e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           3.155838e+05         3.146481e+05   \n",
       "Error Cuadrado Promedio           4.511499e+11         4.604945e+11   \n",
       "Raíz del Error Cuadrado Promedio  6.716769e+05         6.785975e+05   \n",
       "R2                                3.169286e-01         3.027802e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     4.082685e+05       3.109034e+05   \n",
       "Error Cuadrado Promedio                     8.267968e+11       4.464652e+11   \n",
       "Raíz del Error Cuadrado Promedio            9.092837e+05       6.681805e+05   \n",
       "R2                                         -2.518262e-01       3.240215e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           3.181908e+05  \n",
       "Error Cuadrado Promedio           5.062102e+11  \n",
       "Raíz del Error Cuadrado Promedio  7.114845e+05  \n",
       "R2                                2.335634e-01  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ps3eure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ps3eure.to_csv('ps3eure.csv')\n",
    "ps3eure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43\n",
      "[LightGBM] [Info] Number of data points in the train set: 291, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 137697.594502\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ps3jp['Calificacion_critica']\n",
    "y = ps3jp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>1.216978e+05</td>\n",
       "      <td>1.218241e+05</td>\n",
       "      <td>9.706435e+04</td>\n",
       "      <td>1.248073e+05</td>\n",
       "      <td>1.183262e+05</td>\n",
       "      <td>1.256668e+05</td>\n",
       "      <td>1.250000e+05</td>\n",
       "      <td>1.207430e+05</td>\n",
       "      <td>1.194957e+05</td>\n",
       "      <td>1.161085e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>3.004255e+10</td>\n",
       "      <td>2.999957e+10</td>\n",
       "      <td>3.456883e+10</td>\n",
       "      <td>3.846832e+10</td>\n",
       "      <td>3.475005e+10</td>\n",
       "      <td>3.857265e+10</td>\n",
       "      <td>3.992600e+10</td>\n",
       "      <td>4.531561e+10</td>\n",
       "      <td>3.458902e+10</td>\n",
       "      <td>3.193956e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.733279e+05</td>\n",
       "      <td>1.732038e+05</td>\n",
       "      <td>1.859269e+05</td>\n",
       "      <td>1.961334e+05</td>\n",
       "      <td>1.864137e+05</td>\n",
       "      <td>1.963992e+05</td>\n",
       "      <td>1.998149e+05</td>\n",
       "      <td>2.128746e+05</td>\n",
       "      <td>1.859812e+05</td>\n",
       "      <td>1.787164e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>2.295119e-02</td>\n",
       "      <td>2.434901e-02</td>\n",
       "      <td>-1.242532e-01</td>\n",
       "      <td>-2.510733e-01</td>\n",
       "      <td>-1.301471e-01</td>\n",
       "      <td>-2.544664e-01</td>\n",
       "      <td>-2.984802e-01</td>\n",
       "      <td>-4.737620e-01</td>\n",
       "      <td>-1.249099e-01</td>\n",
       "      <td>-3.874377e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           1.216978e+05  1.218241e+05  9.706435e+04   \n",
       "Error Cuadrado Promedio           3.004255e+10  2.999957e+10  3.456883e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.733279e+05  1.732038e+05  1.859269e+05   \n",
       "R2                                2.295119e-02  2.434901e-02 -1.242532e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  1.248073e+05      1.183262e+05   \n",
       "Error Cuadrado Promedio                  3.846832e+10      3.475005e+10   \n",
       "Raíz del Error Cuadrado Promedio         1.961334e+05      1.864137e+05   \n",
       "R2                                      -2.510733e-01     -1.301471e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           1.256668e+05         1.250000e+05   \n",
       "Error Cuadrado Promedio           3.857265e+10         3.992600e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.963992e+05         1.998149e+05   \n",
       "R2                               -2.544664e-01        -2.984802e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     1.207430e+05       1.194957e+05   \n",
       "Error Cuadrado Promedio                     4.531561e+10       3.458902e+10   \n",
       "Raíz del Error Cuadrado Promedio            2.128746e+05       1.859812e+05   \n",
       "R2                                         -4.737620e-01      -1.249099e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           1.161085e+05  \n",
       "Error Cuadrado Promedio           3.193956e+10  \n",
       "Raíz del Error Cuadrado Promedio  1.787164e+05  \n",
       "R2                               -3.874377e-02  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ps3jpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ps3jpre.to_csv('ps3jpre.csv')\n",
    "ps3jpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 55\n",
      "[LightGBM] [Info] Number of data points in the train set: 548, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 435492.700730\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ps3na['Calificacion_critica']\n",
    "y = ps3na['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.682288e+05</td>\n",
       "      <td>3.152281e+05</td>\n",
       "      <td>3.519810e+05</td>\n",
       "      <td>2.974460e+05</td>\n",
       "      <td>2.924015e+05</td>\n",
       "      <td>2.967518e+05</td>\n",
       "      <td>2.777627e+05</td>\n",
       "      <td>4.603999e+05</td>\n",
       "      <td>2.882314e+05</td>\n",
       "      <td>2.830320e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>4.630761e+11</td>\n",
       "      <td>3.819252e+11</td>\n",
       "      <td>6.439863e+11</td>\n",
       "      <td>3.114150e+11</td>\n",
       "      <td>3.040901e+11</td>\n",
       "      <td>3.112015e+11</td>\n",
       "      <td>3.047362e+11</td>\n",
       "      <td>8.012574e+11</td>\n",
       "      <td>3.050292e+11</td>\n",
       "      <td>3.521327e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>6.804969e+05</td>\n",
       "      <td>6.180010e+05</td>\n",
       "      <td>8.024876e+05</td>\n",
       "      <td>5.580457e+05</td>\n",
       "      <td>5.514436e+05</td>\n",
       "      <td>5.578544e+05</td>\n",
       "      <td>5.520292e+05</td>\n",
       "      <td>8.951298e+05</td>\n",
       "      <td>5.522945e+05</td>\n",
       "      <td>5.934077e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>2.147046e-01</td>\n",
       "      <td>3.523222e-01</td>\n",
       "      <td>-9.208725e-02</td>\n",
       "      <td>4.718950e-01</td>\n",
       "      <td>4.843168e-01</td>\n",
       "      <td>4.722570e-01</td>\n",
       "      <td>4.832211e-01</td>\n",
       "      <td>-3.587913e-01</td>\n",
       "      <td>4.827242e-01</td>\n",
       "      <td>4.028449e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.682288e+05  3.152281e+05  3.519810e+05   \n",
       "Error Cuadrado Promedio           4.630761e+11  3.819252e+11  6.439863e+11   \n",
       "Raíz del Error Cuadrado Promedio  6.804969e+05  6.180010e+05  8.024876e+05   \n",
       "R2                                2.147046e-01  3.523222e-01 -9.208725e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.974460e+05      2.924015e+05   \n",
       "Error Cuadrado Promedio                  3.114150e+11      3.040901e+11   \n",
       "Raíz del Error Cuadrado Promedio         5.580457e+05      5.514436e+05   \n",
       "R2                                       4.718950e-01      4.843168e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.967518e+05         2.777627e+05   \n",
       "Error Cuadrado Promedio           3.112015e+11         3.047362e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.578544e+05         5.520292e+05   \n",
       "R2                                4.722570e-01         4.832211e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     4.603999e+05       2.882314e+05   \n",
       "Error Cuadrado Promedio                     8.012574e+11       3.050292e+11   \n",
       "Raíz del Error Cuadrado Promedio            8.951298e+05       5.522945e+05   \n",
       "R2                                         -3.587913e-01       4.827242e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.830320e+05  \n",
       "Error Cuadrado Promedio           3.521327e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.934077e+05  \n",
       "R2                                4.028449e-01  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ps3nare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ps3nare.to_csv('ps3nare.csv')\n",
    "ps3nare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 30\n",
      "[LightGBM] [Info] Number of data points in the train set: 150, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 510800.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ps4eu['Calificacion_critica']\n",
    "y = ps4eu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>4.910785e+05</td>\n",
       "      <td>4.689319e+05</td>\n",
       "      <td>4.836871e+05</td>\n",
       "      <td>4.751827e+05</td>\n",
       "      <td>4.812399e+05</td>\n",
       "      <td>4.924025e+05</td>\n",
       "      <td>4.829846e+05</td>\n",
       "      <td>5.526058e+05</td>\n",
       "      <td>4.673244e+05</td>\n",
       "      <td>4.605518e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>7.434822e+11</td>\n",
       "      <td>6.595412e+11</td>\n",
       "      <td>1.038844e+12</td>\n",
       "      <td>6.965863e+11</td>\n",
       "      <td>7.268638e+11</td>\n",
       "      <td>7.091776e+11</td>\n",
       "      <td>7.912649e+11</td>\n",
       "      <td>1.189795e+12</td>\n",
       "      <td>6.902174e+11</td>\n",
       "      <td>7.621288e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>8.622541e+05</td>\n",
       "      <td>8.121214e+05</td>\n",
       "      <td>1.019237e+06</td>\n",
       "      <td>8.346174e+05</td>\n",
       "      <td>8.525631e+05</td>\n",
       "      <td>8.421269e+05</td>\n",
       "      <td>8.895307e+05</td>\n",
       "      <td>1.090777e+06</td>\n",
       "      <td>8.307932e+05</td>\n",
       "      <td>8.729999e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.593949e-01</td>\n",
       "      <td>2.543013e-01</td>\n",
       "      <td>-1.745513e-01</td>\n",
       "      <td>2.124169e-01</td>\n",
       "      <td>1.781842e-01</td>\n",
       "      <td>1.981807e-01</td>\n",
       "      <td>1.053702e-01</td>\n",
       "      <td>-3.452211e-01</td>\n",
       "      <td>2.196178e-01</td>\n",
       "      <td>1.383124e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           4.910785e+05  4.689319e+05  4.836871e+05   \n",
       "Error Cuadrado Promedio           7.434822e+11  6.595412e+11  1.038844e+12   \n",
       "Raíz del Error Cuadrado Promedio  8.622541e+05  8.121214e+05  1.019237e+06   \n",
       "R2                                1.593949e-01  2.543013e-01 -1.745513e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  4.751827e+05      4.812399e+05   \n",
       "Error Cuadrado Promedio                  6.965863e+11      7.268638e+11   \n",
       "Raíz del Error Cuadrado Promedio         8.346174e+05      8.525631e+05   \n",
       "R2                                       2.124169e-01      1.781842e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           4.924025e+05         4.829846e+05   \n",
       "Error Cuadrado Promedio           7.091776e+11         7.912649e+11   \n",
       "Raíz del Error Cuadrado Promedio  8.421269e+05         8.895307e+05   \n",
       "R2                                1.981807e-01         1.053702e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     5.526058e+05       4.673244e+05   \n",
       "Error Cuadrado Promedio                     1.189795e+12       6.902174e+11   \n",
       "Raíz del Error Cuadrado Promedio            1.090777e+06       8.307932e+05   \n",
       "R2                                         -3.452211e-01       2.196178e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           4.605518e+05  \n",
       "Error Cuadrado Promedio           7.621288e+11  \n",
       "Raíz del Error Cuadrado Promedio  8.729999e+05  \n",
       "R2                                1.383124e-01  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ps4eure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ps4eure.to_csv('ps4eure.csv')\n",
    "ps4eure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23\n",
      "[LightGBM] [Info] Number of data points in the train set: 91, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 73406.593407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ps4jp['Calificacion_critica']\n",
    "y = ps4jp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>4.983869e+04</td>\n",
       "      <td>4.731988e+04</td>\n",
       "      <td>4.640892e+04</td>\n",
       "      <td>5.252137e+04</td>\n",
       "      <td>4.953150e+04</td>\n",
       "      <td>5.264760e+04</td>\n",
       "      <td>4.538462e+04</td>\n",
       "      <td>7.104281e+04</td>\n",
       "      <td>5.010196e+04</td>\n",
       "      <td>4.844976e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>7.198300e+09</td>\n",
       "      <td>6.189623e+09</td>\n",
       "      <td>6.074447e+09</td>\n",
       "      <td>7.417397e+09</td>\n",
       "      <td>7.051488e+09</td>\n",
       "      <td>7.421558e+09</td>\n",
       "      <td>6.329538e+09</td>\n",
       "      <td>1.066879e+10</td>\n",
       "      <td>7.033775e+09</td>\n",
       "      <td>6.564920e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>8.484280e+04</td>\n",
       "      <td>7.867416e+04</td>\n",
       "      <td>7.793874e+04</td>\n",
       "      <td>8.612431e+04</td>\n",
       "      <td>8.397314e+04</td>\n",
       "      <td>8.614847e+04</td>\n",
       "      <td>7.955840e+04</td>\n",
       "      <td>1.032898e+05</td>\n",
       "      <td>8.386761e+04</td>\n",
       "      <td>8.102419e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-2.805097e-01</td>\n",
       "      <td>-1.010756e-01</td>\n",
       "      <td>-8.058682e-02</td>\n",
       "      <td>-3.194851e-01</td>\n",
       "      <td>-2.543933e-01</td>\n",
       "      <td>-3.202252e-01</td>\n",
       "      <td>-1.259652e-01</td>\n",
       "      <td>-8.978764e-01</td>\n",
       "      <td>-2.512423e-01</td>\n",
       "      <td>-1.678374e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           4.983869e+04  4.731988e+04  4.640892e+04   \n",
       "Error Cuadrado Promedio           7.198300e+09  6.189623e+09  6.074447e+09   \n",
       "Raíz del Error Cuadrado Promedio  8.484280e+04  7.867416e+04  7.793874e+04   \n",
       "R2                               -2.805097e-01 -1.010756e-01 -8.058682e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  5.252137e+04      4.953150e+04   \n",
       "Error Cuadrado Promedio                  7.417397e+09      7.051488e+09   \n",
       "Raíz del Error Cuadrado Promedio         8.612431e+04      8.397314e+04   \n",
       "R2                                      -3.194851e-01     -2.543933e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           5.264760e+04         4.538462e+04   \n",
       "Error Cuadrado Promedio           7.421558e+09         6.329538e+09   \n",
       "Raíz del Error Cuadrado Promedio  8.614847e+04         7.955840e+04   \n",
       "R2                               -3.202252e-01        -1.259652e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     7.104281e+04       5.010196e+04   \n",
       "Error Cuadrado Promedio                     1.066879e+10       7.033775e+09   \n",
       "Raíz del Error Cuadrado Promedio            1.032898e+05       8.386761e+04   \n",
       "R2                                         -8.978764e-01      -2.512423e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           4.844976e+04  \n",
       "Error Cuadrado Promedio           6.564920e+09  \n",
       "Raíz del Error Cuadrado Promedio  8.102419e+04  \n",
       "R2                               -1.678374e-01  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ps4jpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ps4jpre.to_csv('ps4jpre.csv')\n",
    "ps4jpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 31\n",
      "[LightGBM] [Info] Number of data points in the train set: 149, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 366979.865772\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ps4na['Calificacion_critica']\n",
    "y = ps4na['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.855646e+05</td>\n",
       "      <td>3.526265e+05</td>\n",
       "      <td>4.090604e+05</td>\n",
       "      <td>3.814093e+05</td>\n",
       "      <td>3.719985e+05</td>\n",
       "      <td>3.806366e+05</td>\n",
       "      <td>3.749375e+05</td>\n",
       "      <td>4.656191e+05</td>\n",
       "      <td>3.773055e+05</td>\n",
       "      <td>3.853970e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>4.071699e+11</td>\n",
       "      <td>3.551900e+11</td>\n",
       "      <td>6.136154e+11</td>\n",
       "      <td>4.008274e+11</td>\n",
       "      <td>3.826201e+11</td>\n",
       "      <td>4.007757e+11</td>\n",
       "      <td>4.311605e+11</td>\n",
       "      <td>7.175265e+11</td>\n",
       "      <td>3.902843e+11</td>\n",
       "      <td>4.263063e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>6.380986e+05</td>\n",
       "      <td>5.959782e+05</td>\n",
       "      <td>7.833361e+05</td>\n",
       "      <td>6.331093e+05</td>\n",
       "      <td>6.185630e+05</td>\n",
       "      <td>6.330685e+05</td>\n",
       "      <td>6.566281e+05</td>\n",
       "      <td>8.470694e+05</td>\n",
       "      <td>6.247274e+05</td>\n",
       "      <td>6.529213e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.868988e-01</td>\n",
       "      <td>2.907004e-01</td>\n",
       "      <td>-2.253643e-01</td>\n",
       "      <td>1.995645e-01</td>\n",
       "      <td>2.359236e-01</td>\n",
       "      <td>1.996677e-01</td>\n",
       "      <td>1.389905e-01</td>\n",
       "      <td>-4.328705e-01</td>\n",
       "      <td>2.206186e-01</td>\n",
       "      <td>1.486842e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.855646e+05  3.526265e+05  4.090604e+05   \n",
       "Error Cuadrado Promedio           4.071699e+11  3.551900e+11  6.136154e+11   \n",
       "Raíz del Error Cuadrado Promedio  6.380986e+05  5.959782e+05  7.833361e+05   \n",
       "R2                                1.868988e-01  2.907004e-01 -2.253643e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  3.814093e+05      3.719985e+05   \n",
       "Error Cuadrado Promedio                  4.008274e+11      3.826201e+11   \n",
       "Raíz del Error Cuadrado Promedio         6.331093e+05      6.185630e+05   \n",
       "R2                                       1.995645e-01      2.359236e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           3.806366e+05         3.749375e+05   \n",
       "Error Cuadrado Promedio           4.007757e+11         4.311605e+11   \n",
       "Raíz del Error Cuadrado Promedio  6.330685e+05         6.566281e+05   \n",
       "R2                                1.996677e-01         1.389905e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     4.656191e+05       3.773055e+05   \n",
       "Error Cuadrado Promedio                     7.175265e+11       3.902843e+11   \n",
       "Raíz del Error Cuadrado Promedio            8.470694e+05       6.247274e+05   \n",
       "R2                                         -4.328705e-01       2.206186e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           3.853970e+05  \n",
       "Error Cuadrado Promedio           4.263063e+11  \n",
       "Raíz del Error Cuadrado Promedio  6.529213e+05  \n",
       "R2                                1.486842e-01  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "ps4nare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "ps4nare.to_csv('ps4nare.csv')\n",
    "ps4nare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34\n",
      "[LightGBM] [Info] Number of data points in the train set: 138, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 381231.884058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = pseu['Calificacion_critica']\n",
    "y = pseu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.345423e+05</td>\n",
       "      <td>3.176550e+05</td>\n",
       "      <td>2.944968e+05</td>\n",
       "      <td>3.870056e+05</td>\n",
       "      <td>3.374538e+05</td>\n",
       "      <td>3.893913e+05</td>\n",
       "      <td>2.763000e+05</td>\n",
       "      <td>3.547341e+05</td>\n",
       "      <td>3.680016e+05</td>\n",
       "      <td>2.810881e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.534351e+11</td>\n",
       "      <td>2.347334e+11</td>\n",
       "      <td>3.543956e+11</td>\n",
       "      <td>4.753831e+11</td>\n",
       "      <td>3.470327e+11</td>\n",
       "      <td>4.762518e+11</td>\n",
       "      <td>2.462202e+11</td>\n",
       "      <td>4.226058e+11</td>\n",
       "      <td>4.554006e+11</td>\n",
       "      <td>2.536433e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>5.034233e+05</td>\n",
       "      <td>4.844930e+05</td>\n",
       "      <td>5.953114e+05</td>\n",
       "      <td>6.894803e+05</td>\n",
       "      <td>5.890948e+05</td>\n",
       "      <td>6.901100e+05</td>\n",
       "      <td>4.962058e+05</td>\n",
       "      <td>6.500814e+05</td>\n",
       "      <td>6.748337e+05</td>\n",
       "      <td>5.036302e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.461035e-01</td>\n",
       "      <td>2.091147e-01</td>\n",
       "      <td>-1.940621e-01</td>\n",
       "      <td>-6.017040e-01</td>\n",
       "      <td>-1.692543e-01</td>\n",
       "      <td>-6.046310e-01</td>\n",
       "      <td>1.704125e-01</td>\n",
       "      <td>-4.238821e-01</td>\n",
       "      <td>-5.343771e-01</td>\n",
       "      <td>1.454017e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.345423e+05  3.176550e+05  2.944968e+05   \n",
       "Error Cuadrado Promedio           2.534351e+11  2.347334e+11  3.543956e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.034233e+05  4.844930e+05  5.953114e+05   \n",
       "R2                                1.461035e-01  2.091147e-01 -1.940621e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  3.870056e+05      3.374538e+05   \n",
       "Error Cuadrado Promedio                  4.753831e+11      3.470327e+11   \n",
       "Raíz del Error Cuadrado Promedio         6.894803e+05      5.890948e+05   \n",
       "R2                                      -6.017040e-01     -1.692543e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           3.893913e+05         2.763000e+05   \n",
       "Error Cuadrado Promedio           4.762518e+11         2.462202e+11   \n",
       "Raíz del Error Cuadrado Promedio  6.901100e+05         4.962058e+05   \n",
       "R2                               -6.046310e-01         1.704125e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     3.547341e+05       3.680016e+05   \n",
       "Error Cuadrado Promedio                     4.226058e+11       4.554006e+11   \n",
       "Raíz del Error Cuadrado Promedio            6.500814e+05       6.748337e+05   \n",
       "R2                                         -4.238821e-01      -5.343771e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.810881e+05  \n",
       "Error Cuadrado Promedio           2.536433e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.036302e+05  \n",
       "R2                                1.454017e-01  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "pseure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "pseure.to_csv('pseure.csv')\n",
    "pseure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13\n",
      "[LightGBM] [Info] Number of data points in the train set: 44, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 657500.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = psjp['Calificacion_critica']\n",
    "y = psjp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>5.162396e+05</td>\n",
       "      <td>4.791781e+05</td>\n",
       "      <td>4.715782e+05</td>\n",
       "      <td>5.766667e+05</td>\n",
       "      <td>5.149535e+05</td>\n",
       "      <td>5.768291e+05</td>\n",
       "      <td>5.122105e+05</td>\n",
       "      <td>6.475791e+05</td>\n",
       "      <td>5.592950e+05</td>\n",
       "      <td>5.377251e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>6.056305e+11</td>\n",
       "      <td>5.763672e+11</td>\n",
       "      <td>7.727993e+11</td>\n",
       "      <td>9.120860e+11</td>\n",
       "      <td>7.376982e+11</td>\n",
       "      <td>9.120810e+11</td>\n",
       "      <td>5.938623e+11</td>\n",
       "      <td>1.091073e+12</td>\n",
       "      <td>8.865539e+11</td>\n",
       "      <td>6.167935e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>7.782226e+05</td>\n",
       "      <td>7.591885e+05</td>\n",
       "      <td>8.790901e+05</td>\n",
       "      <td>9.550319e+05</td>\n",
       "      <td>8.588936e+05</td>\n",
       "      <td>9.550293e+05</td>\n",
       "      <td>7.706246e+05</td>\n",
       "      <td>1.044544e+06</td>\n",
       "      <td>9.415699e+05</td>\n",
       "      <td>7.853620e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>9.841927e-02</td>\n",
       "      <td>1.419824e-01</td>\n",
       "      <td>-1.504391e-01</td>\n",
       "      <td>-3.577902e-01</td>\n",
       "      <td>-9.818525e-02</td>\n",
       "      <td>-3.577827e-01</td>\n",
       "      <td>1.159381e-01</td>\n",
       "      <td>-6.242417e-01</td>\n",
       "      <td>-3.197815e-01</td>\n",
       "      <td>8.180136e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           5.162396e+05  4.791781e+05  4.715782e+05   \n",
       "Error Cuadrado Promedio           6.056305e+11  5.763672e+11  7.727993e+11   \n",
       "Raíz del Error Cuadrado Promedio  7.782226e+05  7.591885e+05  8.790901e+05   \n",
       "R2                                9.841927e-02  1.419824e-01 -1.504391e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  5.766667e+05      5.149535e+05   \n",
       "Error Cuadrado Promedio                  9.120860e+11      7.376982e+11   \n",
       "Raíz del Error Cuadrado Promedio         9.550319e+05      8.588936e+05   \n",
       "R2                                      -3.577902e-01     -9.818525e-02   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           5.768291e+05         5.122105e+05   \n",
       "Error Cuadrado Promedio           9.120810e+11         5.938623e+11   \n",
       "Raíz del Error Cuadrado Promedio  9.550293e+05         7.706246e+05   \n",
       "R2                               -3.577827e-01         1.159381e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     6.475791e+05       5.592950e+05   \n",
       "Error Cuadrado Promedio                     1.091073e+12       8.865539e+11   \n",
       "Raíz del Error Cuadrado Promedio            1.044544e+06       9.415699e+05   \n",
       "R2                                         -6.242417e-01      -3.197815e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           5.377251e+05  \n",
       "Error Cuadrado Promedio           6.167935e+11  \n",
       "Raíz del Error Cuadrado Promedio  7.853620e+05  \n",
       "R2                                8.180136e-02  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "psjpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "psjpre.to_csv('psjpre.csv')\n",
    "psjpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34\n",
      "[LightGBM] [Info] Number of data points in the train set: 138, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 526231.884058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = psna['Calificacion_critica']\n",
    "y = psna['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>4.409637e+05</td>\n",
       "      <td>4.119560e+05</td>\n",
       "      <td>4.459943e+05</td>\n",
       "      <td>3.937238e+05</td>\n",
       "      <td>3.540036e+05</td>\n",
       "      <td>3.970460e+05</td>\n",
       "      <td>3.411667e+05</td>\n",
       "      <td>5.408048e+05</td>\n",
       "      <td>3.656949e+05</td>\n",
       "      <td>3.502682e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>3.972117e+11</td>\n",
       "      <td>3.117206e+11</td>\n",
       "      <td>6.722990e+11</td>\n",
       "      <td>3.362274e+11</td>\n",
       "      <td>2.878742e+11</td>\n",
       "      <td>3.381526e+11</td>\n",
       "      <td>2.771797e+11</td>\n",
       "      <td>8.271053e+11</td>\n",
       "      <td>3.032866e+11</td>\n",
       "      <td>2.981777e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>6.302473e+05</td>\n",
       "      <td>5.583194e+05</td>\n",
       "      <td>8.199384e+05</td>\n",
       "      <td>5.798512e+05</td>\n",
       "      <td>5.365391e+05</td>\n",
       "      <td>5.815089e+05</td>\n",
       "      <td>5.264786e+05</td>\n",
       "      <td>9.094533e+05</td>\n",
       "      <td>5.507146e+05</td>\n",
       "      <td>5.460565e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>2.570932e-01</td>\n",
       "      <td>4.169876e-01</td>\n",
       "      <td>-2.574038e-01</td>\n",
       "      <td>3.711524e-01</td>\n",
       "      <td>4.615875e-01</td>\n",
       "      <td>3.675517e-01</td>\n",
       "      <td>4.815897e-01</td>\n",
       "      <td>-5.469386e-01</td>\n",
       "      <td>4.327618e-01</td>\n",
       "      <td>4.423170e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           4.409637e+05  4.119560e+05  4.459943e+05   \n",
       "Error Cuadrado Promedio           3.972117e+11  3.117206e+11  6.722990e+11   \n",
       "Raíz del Error Cuadrado Promedio  6.302473e+05  5.583194e+05  8.199384e+05   \n",
       "R2                                2.570932e-01  4.169876e-01 -2.574038e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  3.937238e+05      3.540036e+05   \n",
       "Error Cuadrado Promedio                  3.362274e+11      2.878742e+11   \n",
       "Raíz del Error Cuadrado Promedio         5.798512e+05      5.365391e+05   \n",
       "R2                                       3.711524e-01      4.615875e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           3.970460e+05         3.411667e+05   \n",
       "Error Cuadrado Promedio           3.381526e+11         2.771797e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.815089e+05         5.264786e+05   \n",
       "R2                                3.675517e-01         4.815897e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     5.408048e+05       3.656949e+05   \n",
       "Error Cuadrado Promedio                     8.271053e+11       3.032866e+11   \n",
       "Raíz del Error Cuadrado Promedio            9.094533e+05       5.507146e+05   \n",
       "R2                                         -5.469386e-01       4.327618e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           3.502682e+05  \n",
       "Error Cuadrado Promedio           2.981777e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.460565e+05  \n",
       "R2                                4.423170e-01  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "psnare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "psnare.to_csv('psnare.csv')\n",
    "psnare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 33\n",
      "[LightGBM] [Info] Number of data points in the train set: 158, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 222088.607595\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = pspeu['Calificacion_critica']\n",
    "y = pspeu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.009723e+05</td>\n",
       "      <td>2.026774e+05</td>\n",
       "      <td>1.947060e+05</td>\n",
       "      <td>2.328113e+05</td>\n",
       "      <td>2.307288e+05</td>\n",
       "      <td>2.348403e+05</td>\n",
       "      <td>2.131471e+05</td>\n",
       "      <td>2.432219e+05</td>\n",
       "      <td>2.287486e+05</td>\n",
       "      <td>2.282382e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.405431e+11</td>\n",
       "      <td>1.380206e+11</td>\n",
       "      <td>1.618730e+11</td>\n",
       "      <td>1.616566e+11</td>\n",
       "      <td>1.587544e+11</td>\n",
       "      <td>1.619451e+11</td>\n",
       "      <td>1.617572e+11</td>\n",
       "      <td>2.057627e+11</td>\n",
       "      <td>1.574630e+11</td>\n",
       "      <td>1.492708e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>3.748908e+05</td>\n",
       "      <td>3.715112e+05</td>\n",
       "      <td>4.023344e+05</td>\n",
       "      <td>4.020654e+05</td>\n",
       "      <td>3.984399e+05</td>\n",
       "      <td>4.024240e+05</td>\n",
       "      <td>4.021905e+05</td>\n",
       "      <td>4.536107e+05</td>\n",
       "      <td>3.968161e+05</td>\n",
       "      <td>3.863558e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>4.140719e-02</td>\n",
       "      <td>5.861253e-02</td>\n",
       "      <td>-1.040756e-01</td>\n",
       "      <td>-1.025998e-01</td>\n",
       "      <td>-8.280479e-02</td>\n",
       "      <td>-1.045674e-01</td>\n",
       "      <td>-1.032863e-01</td>\n",
       "      <td>-4.034310e-01</td>\n",
       "      <td>-7.399689e-02</td>\n",
       "      <td>-1.812092e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.009723e+05  2.026774e+05  1.947060e+05   \n",
       "Error Cuadrado Promedio           1.405431e+11  1.380206e+11  1.618730e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.748908e+05  3.715112e+05  4.023344e+05   \n",
       "R2                                4.140719e-02  5.861253e-02 -1.040756e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.328113e+05      2.307288e+05   \n",
       "Error Cuadrado Promedio                  1.616566e+11      1.587544e+11   \n",
       "Raíz del Error Cuadrado Promedio         4.020654e+05      3.984399e+05   \n",
       "R2                                      -1.025998e-01     -8.280479e-02   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.348403e+05         2.131471e+05   \n",
       "Error Cuadrado Promedio           1.619451e+11         1.617572e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.024240e+05         4.021905e+05   \n",
       "R2                               -1.045674e-01        -1.032863e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.432219e+05       2.287486e+05   \n",
       "Error Cuadrado Promedio                     2.057627e+11       1.574630e+11   \n",
       "Raíz del Error Cuadrado Promedio            4.536107e+05       3.968161e+05   \n",
       "R2                                         -4.034310e-01      -7.399689e-02   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.282382e+05  \n",
       "Error Cuadrado Promedio           1.492708e+11  \n",
       "Raíz del Error Cuadrado Promedio  3.863558e+05  \n",
       "R2                               -1.812092e-02  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "pspeure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "pspeure.to_csv('pspeure.csv')\n",
    "pspeure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28\n",
      "[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 198000.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = pspjp['Calificacion_critica']\n",
    "y = pspjp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>1.548720e+05</td>\n",
       "      <td>1.540492e+05</td>\n",
       "      <td>9.772672e+04</td>\n",
       "      <td>2.196250e+05</td>\n",
       "      <td>2.026598e+05</td>\n",
       "      <td>2.205317e+05</td>\n",
       "      <td>1.765000e+05</td>\n",
       "      <td>1.279593e+05</td>\n",
       "      <td>2.170240e+05</td>\n",
       "      <td>1.812591e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>3.601506e+10</td>\n",
       "      <td>3.595572e+10</td>\n",
       "      <td>3.252708e+10</td>\n",
       "      <td>1.837205e+11</td>\n",
       "      <td>1.543959e+11</td>\n",
       "      <td>1.838179e+11</td>\n",
       "      <td>8.311009e+10</td>\n",
       "      <td>4.425155e+10</td>\n",
       "      <td>1.761931e+11</td>\n",
       "      <td>7.199406e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.897763e+05</td>\n",
       "      <td>1.896199e+05</td>\n",
       "      <td>1.803526e+05</td>\n",
       "      <td>4.286262e+05</td>\n",
       "      <td>3.929325e+05</td>\n",
       "      <td>4.287400e+05</td>\n",
       "      <td>2.882882e+05</td>\n",
       "      <td>2.103605e+05</td>\n",
       "      <td>4.197536e+05</td>\n",
       "      <td>2.683171e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-2.918573e-01</td>\n",
       "      <td>-2.897286e-01</td>\n",
       "      <td>-1.667437e-01</td>\n",
       "      <td>-5.590038e+00</td>\n",
       "      <td>-4.538170e+00</td>\n",
       "      <td>-5.593535e+00</td>\n",
       "      <td>-1.981152e+00</td>\n",
       "      <td>-5.872994e-01</td>\n",
       "      <td>-5.320033e+00</td>\n",
       "      <td>-1.582421e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           1.548720e+05  1.540492e+05  9.772672e+04   \n",
       "Error Cuadrado Promedio           3.601506e+10  3.595572e+10  3.252708e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.897763e+05  1.896199e+05  1.803526e+05   \n",
       "R2                               -2.918573e-01 -2.897286e-01 -1.667437e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.196250e+05      2.026598e+05   \n",
       "Error Cuadrado Promedio                  1.837205e+11      1.543959e+11   \n",
       "Raíz del Error Cuadrado Promedio         4.286262e+05      3.929325e+05   \n",
       "R2                                      -5.590038e+00     -4.538170e+00   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.205317e+05         1.765000e+05   \n",
       "Error Cuadrado Promedio           1.838179e+11         8.311009e+10   \n",
       "Raíz del Error Cuadrado Promedio  4.287400e+05         2.882882e+05   \n",
       "R2                               -5.593535e+00        -1.981152e+00   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     1.279593e+05       2.170240e+05   \n",
       "Error Cuadrado Promedio                     4.425155e+10       1.761931e+11   \n",
       "Raíz del Error Cuadrado Promedio            2.103605e+05       4.197536e+05   \n",
       "R2                                         -5.872994e-01      -5.320033e+00   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           1.812591e+05  \n",
       "Error Cuadrado Promedio           7.199406e+10  \n",
       "Raíz del Error Cuadrado Promedio  2.683171e+05  \n",
       "R2                               -1.582421e+00  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "pspjpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "pspjpre.to_csv('pspjpre.csv')\n",
    "pspjpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46\n",
      "[LightGBM] [Info] Number of data points in the train set: 312, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 195032.051282\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = pspna['Calificacion_critica']\n",
    "y = pspna['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>1.672765e+05</td>\n",
       "      <td>1.637334e+05</td>\n",
       "      <td>1.480698e+05</td>\n",
       "      <td>1.829655e+05</td>\n",
       "      <td>1.829693e+05</td>\n",
       "      <td>1.780730e+05</td>\n",
       "      <td>1.849630e+05</td>\n",
       "      <td>2.064490e+05</td>\n",
       "      <td>1.784048e+05</td>\n",
       "      <td>1.688119e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>8.019289e+10</td>\n",
       "      <td>7.971110e+10</td>\n",
       "      <td>9.682333e+10</td>\n",
       "      <td>1.026942e+11</td>\n",
       "      <td>1.010132e+11</td>\n",
       "      <td>1.012885e+11</td>\n",
       "      <td>9.802847e+10</td>\n",
       "      <td>1.298992e+11</td>\n",
       "      <td>9.868695e+10</td>\n",
       "      <td>8.292915e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>2.831835e+05</td>\n",
       "      <td>2.823315e+05</td>\n",
       "      <td>3.111645e+05</td>\n",
       "      <td>3.204593e+05</td>\n",
       "      <td>3.178258e+05</td>\n",
       "      <td>3.182585e+05</td>\n",
       "      <td>3.130950e+05</td>\n",
       "      <td>3.604153e+05</td>\n",
       "      <td>3.141448e+05</td>\n",
       "      <td>2.879742e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>8.148760e-02</td>\n",
       "      <td>8.700596e-02</td>\n",
       "      <td>-1.089939e-01</td>\n",
       "      <td>-1.762372e-01</td>\n",
       "      <td>-1.569842e-01</td>\n",
       "      <td>-1.601366e-01</td>\n",
       "      <td>-1.227974e-01</td>\n",
       "      <td>-4.878375e-01</td>\n",
       "      <td>-1.303394e-01</td>\n",
       "      <td>5.014702e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           1.672765e+05  1.637334e+05  1.480698e+05   \n",
       "Error Cuadrado Promedio           8.019289e+10  7.971110e+10  9.682333e+10   \n",
       "Raíz del Error Cuadrado Promedio  2.831835e+05  2.823315e+05  3.111645e+05   \n",
       "R2                                8.148760e-02  8.700596e-02 -1.089939e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  1.829655e+05      1.829693e+05   \n",
       "Error Cuadrado Promedio                  1.026942e+11      1.010132e+11   \n",
       "Raíz del Error Cuadrado Promedio         3.204593e+05      3.178258e+05   \n",
       "R2                                      -1.762372e-01     -1.569842e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           1.780730e+05         1.849630e+05   \n",
       "Error Cuadrado Promedio           1.012885e+11         9.802847e+10   \n",
       "Raíz del Error Cuadrado Promedio  3.182585e+05         3.130950e+05   \n",
       "R2                               -1.601366e-01        -1.227974e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.064490e+05       1.784048e+05   \n",
       "Error Cuadrado Promedio                     1.298992e+11       9.868695e+10   \n",
       "Raíz del Error Cuadrado Promedio            3.604153e+05       3.141448e+05   \n",
       "R2                                         -4.878375e-01      -1.303394e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           1.688119e+05  \n",
       "Error Cuadrado Promedio           8.292915e+10  \n",
       "Raíz del Error Cuadrado Promedio  2.879742e+05  \n",
       "R2                                5.014702e-02  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "pspnare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "pspnare.to_csv('pspnare.csv')\n",
    "pspnare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17\n",
      "[LightGBM] [Info] Number of data points in the train set: 65, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 105230.769231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = psveu['Calificacion_critica']\n",
    "y = psveu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>8.706355e+04</td>\n",
       "      <td>8.360205e+04</td>\n",
       "      <td>5.413760e+04</td>\n",
       "      <td>9.727011e+04</td>\n",
       "      <td>9.397124e+04</td>\n",
       "      <td>1.076146e+05</td>\n",
       "      <td>7.965517e+04</td>\n",
       "      <td>7.075939e+04</td>\n",
       "      <td>9.346383e+04</td>\n",
       "      <td>9.129770e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.192083e+10</td>\n",
       "      <td>1.243094e+10</td>\n",
       "      <td>1.074136e+10</td>\n",
       "      <td>1.957033e+10</td>\n",
       "      <td>1.954581e+10</td>\n",
       "      <td>2.391508e+10</td>\n",
       "      <td>1.389007e+10</td>\n",
       "      <td>1.530566e+10</td>\n",
       "      <td>1.829961e+10</td>\n",
       "      <td>1.473975e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.091825e+05</td>\n",
       "      <td>1.114941e+05</td>\n",
       "      <td>1.036405e+05</td>\n",
       "      <td>1.398940e+05</td>\n",
       "      <td>1.398063e+05</td>\n",
       "      <td>1.546450e+05</td>\n",
       "      <td>1.178561e+05</td>\n",
       "      <td>1.237161e+05</td>\n",
       "      <td>1.352761e+05</td>\n",
       "      <td>1.214074e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-1.574821e-01</td>\n",
       "      <td>-2.070131e-01</td>\n",
       "      <td>-4.295854e-02</td>\n",
       "      <td>-9.002295e-01</td>\n",
       "      <td>-8.978488e-01</td>\n",
       "      <td>-1.322094e+00</td>\n",
       "      <td>-3.486905e-01</td>\n",
       "      <td>-4.861411e-01</td>\n",
       "      <td>-7.768463e-01</td>\n",
       "      <td>-4.311920e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           8.706355e+04  8.360205e+04  5.413760e+04   \n",
       "Error Cuadrado Promedio           1.192083e+10  1.243094e+10  1.074136e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.091825e+05  1.114941e+05  1.036405e+05   \n",
       "R2                               -1.574821e-01 -2.070131e-01 -4.295854e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  9.727011e+04      9.397124e+04   \n",
       "Error Cuadrado Promedio                  1.957033e+10      1.954581e+10   \n",
       "Raíz del Error Cuadrado Promedio         1.398940e+05      1.398063e+05   \n",
       "R2                                      -9.002295e-01     -8.978488e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           1.076146e+05         7.965517e+04   \n",
       "Error Cuadrado Promedio           2.391508e+10         1.389007e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.546450e+05         1.178561e+05   \n",
       "R2                               -1.322094e+00        -3.486905e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     7.075939e+04       9.346383e+04   \n",
       "Error Cuadrado Promedio                     1.530566e+10       1.829961e+10   \n",
       "Raíz del Error Cuadrado Promedio            1.237161e+05       1.352761e+05   \n",
       "R2                                         -4.861411e-01      -7.768463e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           9.129770e+04  \n",
       "Error Cuadrado Promedio           1.473975e+10  \n",
       "Raíz del Error Cuadrado Promedio  1.214074e+05  \n",
       "R2                               -4.311920e-01  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "psveure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "psveure.to_csv('psveure.csv')\n",
    "psveure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18\n",
      "[LightGBM] [Info] Number of data points in the train set: 60, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 95166.666667\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = psvjp['Calificacion_critica']\n",
    "y = psvjp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>4.760140e+04</td>\n",
       "      <td>4.852806e+04</td>\n",
       "      <td>4.296223e+04</td>\n",
       "      <td>7.666667e+04</td>\n",
       "      <td>6.132004e+04</td>\n",
       "      <td>7.197456e+04</td>\n",
       "      <td>4.155556e+04</td>\n",
       "      <td>7.294573e+04</td>\n",
       "      <td>7.261728e+04</td>\n",
       "      <td>4.520642e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>3.542630e+09</td>\n",
       "      <td>3.671712e+09</td>\n",
       "      <td>2.555357e+09</td>\n",
       "      <td>1.113498e+10</td>\n",
       "      <td>6.317597e+09</td>\n",
       "      <td>9.941325e+09</td>\n",
       "      <td>2.999556e+09</td>\n",
       "      <td>7.698816e+09</td>\n",
       "      <td>1.005820e+10</td>\n",
       "      <td>3.322132e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>5.951999e+04</td>\n",
       "      <td>6.059466e+04</td>\n",
       "      <td>5.055053e+04</td>\n",
       "      <td>1.055224e+05</td>\n",
       "      <td>7.948331e+04</td>\n",
       "      <td>9.970619e+04</td>\n",
       "      <td>5.476820e+04</td>\n",
       "      <td>8.774290e+04</td>\n",
       "      <td>1.002906e+05</td>\n",
       "      <td>5.763794e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-4.898909e-01</td>\n",
       "      <td>-5.441781e-01</td>\n",
       "      <td>-7.468267e-02</td>\n",
       "      <td>-3.682935e+00</td>\n",
       "      <td>-1.656933e+00</td>\n",
       "      <td>-3.180931e+00</td>\n",
       "      <td>-2.614953e-01</td>\n",
       "      <td>-2.237820e+00</td>\n",
       "      <td>-3.230085e+00</td>\n",
       "      <td>-3.971585e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           4.760140e+04  4.852806e+04  4.296223e+04   \n",
       "Error Cuadrado Promedio           3.542630e+09  3.671712e+09  2.555357e+09   \n",
       "Raíz del Error Cuadrado Promedio  5.951999e+04  6.059466e+04  5.055053e+04   \n",
       "R2                               -4.898909e-01 -5.441781e-01 -7.468267e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  7.666667e+04      6.132004e+04   \n",
       "Error Cuadrado Promedio                  1.113498e+10      6.317597e+09   \n",
       "Raíz del Error Cuadrado Promedio         1.055224e+05      7.948331e+04   \n",
       "R2                                      -3.682935e+00     -1.656933e+00   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           7.197456e+04         4.155556e+04   \n",
       "Error Cuadrado Promedio           9.941325e+09         2.999556e+09   \n",
       "Raíz del Error Cuadrado Promedio  9.970619e+04         5.476820e+04   \n",
       "R2                               -3.180931e+00        -2.614953e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     7.294573e+04       7.261728e+04   \n",
       "Error Cuadrado Promedio                     7.698816e+09       1.005820e+10   \n",
       "Raíz del Error Cuadrado Promedio            8.774290e+04       1.002906e+05   \n",
       "R2                                         -2.237820e+00      -3.230085e+00   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           4.520642e+04  \n",
       "Error Cuadrado Promedio           3.322132e+09  \n",
       "Raíz del Error Cuadrado Promedio  5.763794e+04  \n",
       "R2                               -3.971585e-01  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "psvjpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "psvjpre.to_csv('psvjpre.csv')\n",
    "psvjpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18\n",
      "[LightGBM] [Info] Number of data points in the train set: 63, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 122222.222222\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = psvna['Calificacion_critica']\n",
    "y = psvna['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>7.880695e+04</td>\n",
       "      <td>1.002941e+05</td>\n",
       "      <td>5.592762e+04</td>\n",
       "      <td>8.874074e+04</td>\n",
       "      <td>8.230297e+04</td>\n",
       "      <td>1.252760e+05</td>\n",
       "      <td>7.081481e+04</td>\n",
       "      <td>8.680174e+04</td>\n",
       "      <td>8.312256e+04</td>\n",
       "      <td>7.995853e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.140293e+10</td>\n",
       "      <td>1.990647e+10</td>\n",
       "      <td>9.796351e+09</td>\n",
       "      <td>1.877746e+10</td>\n",
       "      <td>1.663522e+10</td>\n",
       "      <td>3.894526e+10</td>\n",
       "      <td>1.411496e+10</td>\n",
       "      <td>1.728047e+10</td>\n",
       "      <td>1.742632e+10</td>\n",
       "      <td>1.347679e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.067845e+05</td>\n",
       "      <td>1.410903e+05</td>\n",
       "      <td>9.897652e+04</td>\n",
       "      <td>1.370309e+05</td>\n",
       "      <td>1.289776e+05</td>\n",
       "      <td>1.973455e+05</td>\n",
       "      <td>1.188064e+05</td>\n",
       "      <td>1.314552e+05</td>\n",
       "      <td>1.320088e+05</td>\n",
       "      <td>1.160896e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-1.699183e-01</td>\n",
       "      <td>-1.042364e+00</td>\n",
       "      <td>-5.086261e-03</td>\n",
       "      <td>-9.265300e-01</td>\n",
       "      <td>-7.067405e-01</td>\n",
       "      <td>-2.995707e+00</td>\n",
       "      <td>-4.481673e-01</td>\n",
       "      <td>-7.729425e-01</td>\n",
       "      <td>-7.879061e-01</td>\n",
       "      <td>-3.826920e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           7.880695e+04  1.002941e+05  5.592762e+04   \n",
       "Error Cuadrado Promedio           1.140293e+10  1.990647e+10  9.796351e+09   \n",
       "Raíz del Error Cuadrado Promedio  1.067845e+05  1.410903e+05  9.897652e+04   \n",
       "R2                               -1.699183e-01 -1.042364e+00 -5.086261e-03   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  8.874074e+04      8.230297e+04   \n",
       "Error Cuadrado Promedio                  1.877746e+10      1.663522e+10   \n",
       "Raíz del Error Cuadrado Promedio         1.370309e+05      1.289776e+05   \n",
       "R2                                      -9.265300e-01     -7.067405e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           1.252760e+05         7.081481e+04   \n",
       "Error Cuadrado Promedio           3.894526e+10         1.411496e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.973455e+05         1.188064e+05   \n",
       "R2                               -2.995707e+00        -4.481673e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     8.680174e+04       8.312256e+04   \n",
       "Error Cuadrado Promedio                     1.728047e+10       1.742632e+10   \n",
       "Raíz del Error Cuadrado Promedio            1.314552e+05       1.320088e+05   \n",
       "R2                                         -7.729425e-01      -7.879061e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           7.995853e+04  \n",
       "Error Cuadrado Promedio           1.347679e+10  \n",
       "Raíz del Error Cuadrado Promedio  1.160896e+05  \n",
       "R2                               -3.826920e-01  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "psvnare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "psvnare.to_csv('psvnare.csv')\n",
    "psvnare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 47\n",
      "[LightGBM] [Info] Number of data points in the train set: 296, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 520337.837838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = wiieu['Calificacion_critica']\n",
    "y = wiieu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>5.962613e+05</td>\n",
       "      <td>5.731708e+05</td>\n",
       "      <td>4.249187e+05</td>\n",
       "      <td>6.951708e+05</td>\n",
       "      <td>7.054000e+05</td>\n",
       "      <td>6.950386e+05</td>\n",
       "      <td>5.849375e+05</td>\n",
       "      <td>4.540304e+05</td>\n",
       "      <td>6.803489e+05</td>\n",
       "      <td>6.892440e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.454776e+12</td>\n",
       "      <td>1.424810e+12</td>\n",
       "      <td>1.638375e+12</td>\n",
       "      <td>2.177210e+12</td>\n",
       "      <td>2.200412e+12</td>\n",
       "      <td>2.176964e+12</td>\n",
       "      <td>1.770881e+12</td>\n",
       "      <td>1.738837e+12</td>\n",
       "      <td>2.126686e+12</td>\n",
       "      <td>1.860464e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.206141e+06</td>\n",
       "      <td>1.193654e+06</td>\n",
       "      <td>1.279990e+06</td>\n",
       "      <td>1.475537e+06</td>\n",
       "      <td>1.483379e+06</td>\n",
       "      <td>1.475454e+06</td>\n",
       "      <td>1.330745e+06</td>\n",
       "      <td>1.318650e+06</td>\n",
       "      <td>1.458316e+06</td>\n",
       "      <td>1.363988e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>5.090758e-02</td>\n",
       "      <td>7.045767e-02</td>\n",
       "      <td>-6.887167e-02</td>\n",
       "      <td>-4.204064e-01</td>\n",
       "      <td>-4.355436e-01</td>\n",
       "      <td>-4.202459e-01</td>\n",
       "      <td>-1.553185e-01</td>\n",
       "      <td>-1.344130e-01</td>\n",
       "      <td>-3.874445e-01</td>\n",
       "      <td>-2.137620e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           5.962613e+05  5.731708e+05  4.249187e+05   \n",
       "Error Cuadrado Promedio           1.454776e+12  1.424810e+12  1.638375e+12   \n",
       "Raíz del Error Cuadrado Promedio  1.206141e+06  1.193654e+06  1.279990e+06   \n",
       "R2                                5.090758e-02  7.045767e-02 -6.887167e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  6.951708e+05      7.054000e+05   \n",
       "Error Cuadrado Promedio                  2.177210e+12      2.200412e+12   \n",
       "Raíz del Error Cuadrado Promedio         1.475537e+06      1.483379e+06   \n",
       "R2                                      -4.204064e-01     -4.355436e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           6.950386e+05         5.849375e+05   \n",
       "Error Cuadrado Promedio           2.176964e+12         1.770881e+12   \n",
       "Raíz del Error Cuadrado Promedio  1.475454e+06         1.330745e+06   \n",
       "R2                               -4.202459e-01        -1.553185e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     4.540304e+05       6.803489e+05   \n",
       "Error Cuadrado Promedio                     1.738837e+12       2.126686e+12   \n",
       "Raíz del Error Cuadrado Promedio            1.318650e+06       1.458316e+06   \n",
       "R2                                         -1.344130e-01      -3.874445e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           6.892440e+05  \n",
       "Error Cuadrado Promedio           1.860464e+12  \n",
       "Raíz del Error Cuadrado Promedio  1.363988e+06  \n",
       "R2                               -2.137620e-01  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "wiieure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "wiieure.to_csv('wiieure.csv')\n",
    "wiieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 26\n",
      "[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 408476.190476\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = wiijp['Calificacion_critica']\n",
    "y = wiijp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.875338e+05</td>\n",
       "      <td>3.667401e+05</td>\n",
       "      <td>1.951109e+05</td>\n",
       "      <td>3.781365e+05</td>\n",
       "      <td>3.432145e+05</td>\n",
       "      <td>3.248969e+05</td>\n",
       "      <td>4.184889e+05</td>\n",
       "      <td>2.206075e+05</td>\n",
       "      <td>3.653421e+05</td>\n",
       "      <td>3.755821e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>3.425102e+11</td>\n",
       "      <td>3.420431e+11</td>\n",
       "      <td>3.466218e+11</td>\n",
       "      <td>5.331810e+11</td>\n",
       "      <td>3.784580e+11</td>\n",
       "      <td>3.944536e+11</td>\n",
       "      <td>4.082585e+11</td>\n",
       "      <td>3.693928e+11</td>\n",
       "      <td>4.938808e+11</td>\n",
       "      <td>3.470125e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>5.852438e+05</td>\n",
       "      <td>5.848445e+05</td>\n",
       "      <td>5.887459e+05</td>\n",
       "      <td>7.301925e+05</td>\n",
       "      <td>6.151894e+05</td>\n",
       "      <td>6.280554e+05</td>\n",
       "      <td>6.389511e+05</td>\n",
       "      <td>6.077770e+05</td>\n",
       "      <td>7.027665e+05</td>\n",
       "      <td>5.890777e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-6.788510e-02</td>\n",
       "      <td>-6.642850e-02</td>\n",
       "      <td>-8.070405e-02</td>\n",
       "      <td>-6.623622e-01</td>\n",
       "      <td>-1.799638e-01</td>\n",
       "      <td>-2.298350e-01</td>\n",
       "      <td>-2.728762e-01</td>\n",
       "      <td>-1.517002e-01</td>\n",
       "      <td>-5.398312e-01</td>\n",
       "      <td>-8.192233e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.875338e+05  3.667401e+05  1.951109e+05   \n",
       "Error Cuadrado Promedio           3.425102e+11  3.420431e+11  3.466218e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.852438e+05  5.848445e+05  5.887459e+05   \n",
       "R2                               -6.788510e-02 -6.642850e-02 -8.070405e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  3.781365e+05      3.432145e+05   \n",
       "Error Cuadrado Promedio                  5.331810e+11      3.784580e+11   \n",
       "Raíz del Error Cuadrado Promedio         7.301925e+05      6.151894e+05   \n",
       "R2                                      -6.623622e-01     -1.799638e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           3.248969e+05         4.184889e+05   \n",
       "Error Cuadrado Promedio           3.944536e+11         4.082585e+11   \n",
       "Raíz del Error Cuadrado Promedio  6.280554e+05         6.389511e+05   \n",
       "R2                               -2.298350e-01        -2.728762e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.206075e+05       3.653421e+05   \n",
       "Error Cuadrado Promedio                     3.693928e+11       4.938808e+11   \n",
       "Raíz del Error Cuadrado Promedio            6.077770e+05       7.027665e+05   \n",
       "R2                                         -1.517002e-01      -5.398312e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           3.755821e+05  \n",
       "Error Cuadrado Promedio           3.470125e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.890777e+05  \n",
       "R2                               -8.192233e-02  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "wiijpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "wiijpre.to_csv('wiijpre.csv')\n",
    "wiijpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18\n",
      "[LightGBM] [Info] Number of data points in the train set: 58, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 280862.068966\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = wiiueu['Calificacion_critica']\n",
    "y = wiiueu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>1.902391e+05</td>\n",
       "      <td>1.842485e+05</td>\n",
       "      <td>1.190000e+05</td>\n",
       "      <td>1.806000e+05</td>\n",
       "      <td>1.740056e+05</td>\n",
       "      <td>1.809935e+05</td>\n",
       "      <td>1.747200e+05</td>\n",
       "      <td>1.681249e+05</td>\n",
       "      <td>1.781723e+05</td>\n",
       "      <td>2.003447e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>6.692437e+10</td>\n",
       "      <td>6.946780e+10</td>\n",
       "      <td>5.453576e+10</td>\n",
       "      <td>7.925383e+10</td>\n",
       "      <td>7.576442e+10</td>\n",
       "      <td>7.925001e+10</td>\n",
       "      <td>6.899232e+10</td>\n",
       "      <td>8.167938e+10</td>\n",
       "      <td>7.696835e+10</td>\n",
       "      <td>7.813937e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>2.586974e+05</td>\n",
       "      <td>2.635675e+05</td>\n",
       "      <td>2.335289e+05</td>\n",
       "      <td>2.815206e+05</td>\n",
       "      <td>2.752534e+05</td>\n",
       "      <td>2.815138e+05</td>\n",
       "      <td>2.626639e+05</td>\n",
       "      <td>2.857960e+05</td>\n",
       "      <td>2.774317e+05</td>\n",
       "      <td>2.795342e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-2.527624e-01</td>\n",
       "      <td>-3.003730e-01</td>\n",
       "      <td>-2.085895e-02</td>\n",
       "      <td>-4.835585e-01</td>\n",
       "      <td>-4.182400e-01</td>\n",
       "      <td>-4.834870e-01</td>\n",
       "      <td>-2.914725e-01</td>\n",
       "      <td>-5.289624e-01</td>\n",
       "      <td>-4.407764e-01</td>\n",
       "      <td>-4.626967e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           1.902391e+05  1.842485e+05  1.190000e+05   \n",
       "Error Cuadrado Promedio           6.692437e+10  6.946780e+10  5.453576e+10   \n",
       "Raíz del Error Cuadrado Promedio  2.586974e+05  2.635675e+05  2.335289e+05   \n",
       "R2                               -2.527624e-01 -3.003730e-01 -2.085895e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  1.806000e+05      1.740056e+05   \n",
       "Error Cuadrado Promedio                  7.925383e+10      7.576442e+10   \n",
       "Raíz del Error Cuadrado Promedio         2.815206e+05      2.752534e+05   \n",
       "R2                                      -4.835585e-01     -4.182400e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           1.809935e+05         1.747200e+05   \n",
       "Error Cuadrado Promedio           7.925001e+10         6.899232e+10   \n",
       "Raíz del Error Cuadrado Promedio  2.815138e+05         2.626639e+05   \n",
       "R2                               -4.834870e-01        -2.914725e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     1.681249e+05       1.781723e+05   \n",
       "Error Cuadrado Promedio                     8.167938e+10       7.696835e+10   \n",
       "Raíz del Error Cuadrado Promedio            2.857960e+05       2.774317e+05   \n",
       "R2                                         -5.289624e-01      -4.407764e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.003447e+05  \n",
       "Error Cuadrado Promedio           7.813937e+10  \n",
       "Raíz del Error Cuadrado Promedio  2.795342e+05  \n",
       "R2                               -4.626967e-01  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "wiiueure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "wiiueure.to_csv('wiiueure.csv')\n",
    "wiiueure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 31, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 246774.193548\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = wiiujp['Calificacion_critica']\n",
    "y = wiiujp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.589631e+05</td>\n",
       "      <td>2.333444e+05</td>\n",
       "      <td>1.857133e+05</td>\n",
       "      <td>2.639286e+05</td>\n",
       "      <td>2.837412e+05</td>\n",
       "      <td>2.689285e+05</td>\n",
       "      <td>3.088571e+05</td>\n",
       "      <td>1.796515e+05</td>\n",
       "      <td>2.618099e+05</td>\n",
       "      <td>2.705530e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.349595e+11</td>\n",
       "      <td>1.442729e+11</td>\n",
       "      <td>1.443568e+11</td>\n",
       "      <td>2.248232e+11</td>\n",
       "      <td>1.985481e+11</td>\n",
       "      <td>2.252731e+11</td>\n",
       "      <td>2.037343e+11</td>\n",
       "      <td>1.717234e+11</td>\n",
       "      <td>2.230620e+11</td>\n",
       "      <td>1.439159e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>3.673683e+05</td>\n",
       "      <td>3.798327e+05</td>\n",
       "      <td>3.799432e+05</td>\n",
       "      <td>4.741553e+05</td>\n",
       "      <td>4.455873e+05</td>\n",
       "      <td>4.746295e+05</td>\n",
       "      <td>4.513693e+05</td>\n",
       "      <td>4.143952e+05</td>\n",
       "      <td>4.722944e+05</td>\n",
       "      <td>3.793625e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>3.225122e-02</td>\n",
       "      <td>-3.453222e-02</td>\n",
       "      <td>-3.513390e-02</td>\n",
       "      <td>-6.121312e-01</td>\n",
       "      <td>-4.237212e-01</td>\n",
       "      <td>-6.153575e-01</td>\n",
       "      <td>-4.609096e-01</td>\n",
       "      <td>-2.313703e-01</td>\n",
       "      <td>-5.995025e-01</td>\n",
       "      <td>-3.197250e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.589631e+05  2.333444e+05  1.857133e+05   \n",
       "Error Cuadrado Promedio           1.349595e+11  1.442729e+11  1.443568e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.673683e+05  3.798327e+05  3.799432e+05   \n",
       "R2                                3.225122e-02 -3.453222e-02 -3.513390e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.639286e+05      2.837412e+05   \n",
       "Error Cuadrado Promedio                  2.248232e+11      1.985481e+11   \n",
       "Raíz del Error Cuadrado Promedio         4.741553e+05      4.455873e+05   \n",
       "R2                                      -6.121312e-01     -4.237212e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.689285e+05         3.088571e+05   \n",
       "Error Cuadrado Promedio           2.252731e+11         2.037343e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.746295e+05         4.513693e+05   \n",
       "R2                               -6.153575e-01        -4.609096e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     1.796515e+05       2.618099e+05   \n",
       "Error Cuadrado Promedio                     1.717234e+11       2.230620e+11   \n",
       "Raíz del Error Cuadrado Promedio            4.143952e+05       4.722944e+05   \n",
       "R2                                         -2.313703e-01      -5.995025e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.705530e+05  \n",
       "Error Cuadrado Promedio           1.439159e+11  \n",
       "Raíz del Error Cuadrado Promedio  3.793625e+05  \n",
       "R2                               -3.197250e-02  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "wiiujpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "wiiujpre.to_csv('wiiujpre.csv')\n",
    "wiiujpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18\n",
      "[LightGBM] [Info] Number of data points in the train set: 57, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 434561.403509\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = wiiuna['Calificacion_critica']\n",
    "y = wiiuna['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.036023e+05</td>\n",
       "      <td>2.445566e+05</td>\n",
       "      <td>1.587982e+05</td>\n",
       "      <td>2.147000e+05</td>\n",
       "      <td>2.115981e+05</td>\n",
       "      <td>2.147032e+05</td>\n",
       "      <td>2.741600e+05</td>\n",
       "      <td>2.400992e+05</td>\n",
       "      <td>2.129440e+05</td>\n",
       "      <td>2.249478e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.327678e+11</td>\n",
       "      <td>1.110987e+11</td>\n",
       "      <td>9.080300e+10</td>\n",
       "      <td>1.163446e+11</td>\n",
       "      <td>1.211877e+11</td>\n",
       "      <td>1.163522e+11</td>\n",
       "      <td>1.709042e+11</td>\n",
       "      <td>1.480241e+11</td>\n",
       "      <td>1.156337e+11</td>\n",
       "      <td>1.020706e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>3.643732e+05</td>\n",
       "      <td>3.333147e+05</td>\n",
       "      <td>3.013354e+05</td>\n",
       "      <td>3.410933e+05</td>\n",
       "      <td>3.481202e+05</td>\n",
       "      <td>3.411044e+05</td>\n",
       "      <td>4.134056e+05</td>\n",
       "      <td>3.847389e+05</td>\n",
       "      <td>3.400496e+05</td>\n",
       "      <td>3.194850e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-4.688682e-01</td>\n",
       "      <td>-2.291331e-01</td>\n",
       "      <td>-4.593129e-03</td>\n",
       "      <td>-2.871714e-01</td>\n",
       "      <td>-3.407521e-01</td>\n",
       "      <td>-2.872548e-01</td>\n",
       "      <td>-8.907871e-01</td>\n",
       "      <td>-6.376546e-01</td>\n",
       "      <td>-2.793061e-01</td>\n",
       "      <td>-1.292520e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.036023e+05  2.445566e+05  1.587982e+05   \n",
       "Error Cuadrado Promedio           1.327678e+11  1.110987e+11  9.080300e+10   \n",
       "Raíz del Error Cuadrado Promedio  3.643732e+05  3.333147e+05  3.013354e+05   \n",
       "R2                               -4.688682e-01 -2.291331e-01 -4.593129e-03   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.147000e+05      2.115981e+05   \n",
       "Error Cuadrado Promedio                  1.163446e+11      1.211877e+11   \n",
       "Raíz del Error Cuadrado Promedio         3.410933e+05      3.481202e+05   \n",
       "R2                                      -2.871714e-01     -3.407521e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.147032e+05         2.741600e+05   \n",
       "Error Cuadrado Promedio           1.163522e+11         1.709042e+11   \n",
       "Raíz del Error Cuadrado Promedio  3.411044e+05         4.134056e+05   \n",
       "R2                               -2.872548e-01        -8.907871e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.400992e+05       2.129440e+05   \n",
       "Error Cuadrado Promedio                     1.480241e+11       1.156337e+11   \n",
       "Raíz del Error Cuadrado Promedio            3.847389e+05       3.400496e+05   \n",
       "R2                                         -6.376546e-01      -2.793061e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.249478e+05  \n",
       "Error Cuadrado Promedio           1.020706e+11  \n",
       "Raíz del Error Cuadrado Promedio  3.194850e+05  \n",
       "R2                               -1.292520e-01  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "wiiunare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "wiiunare.to_csv('wiiunare.csv')\n",
    "wiiunare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 61\n",
      "[LightGBM] [Info] Number of data points in the train set: 547, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 299287.020110\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = x360eu['Calificacion_critica']\n",
    "y = x360eu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.844467e+05</td>\n",
       "      <td>2.796262e+05</td>\n",
       "      <td>2.739287e+05</td>\n",
       "      <td>2.764243e+05</td>\n",
       "      <td>2.742141e+05</td>\n",
       "      <td>2.764097e+05</td>\n",
       "      <td>2.760766e+05</td>\n",
       "      <td>3.122055e+05</td>\n",
       "      <td>2.729002e+05</td>\n",
       "      <td>2.667584e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.716551e+11</td>\n",
       "      <td>2.836186e+11</td>\n",
       "      <td>3.321078e+11</td>\n",
       "      <td>3.037660e+11</td>\n",
       "      <td>2.998091e+11</td>\n",
       "      <td>3.037465e+11</td>\n",
       "      <td>2.855807e+11</td>\n",
       "      <td>3.953708e+11</td>\n",
       "      <td>3.012276e+11</td>\n",
       "      <td>2.846350e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>5.212054e+05</td>\n",
       "      <td>5.325586e+05</td>\n",
       "      <td>5.762879e+05</td>\n",
       "      <td>5.511497e+05</td>\n",
       "      <td>5.475483e+05</td>\n",
       "      <td>5.511320e+05</td>\n",
       "      <td>5.343975e+05</td>\n",
       "      <td>6.287851e+05</td>\n",
       "      <td>5.488420e+05</td>\n",
       "      <td>5.335120e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>8.861416e-02</td>\n",
       "      <td>4.847734e-02</td>\n",
       "      <td>-1.142007e-01</td>\n",
       "      <td>-1.911587e-02</td>\n",
       "      <td>-5.840715e-03</td>\n",
       "      <td>-1.905040e-02</td>\n",
       "      <td>4.189473e-02</td>\n",
       "      <td>-3.264441e-01</td>\n",
       "      <td>-1.059967e-02</td>\n",
       "      <td>4.506730e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.844467e+05  2.796262e+05  2.739287e+05   \n",
       "Error Cuadrado Promedio           2.716551e+11  2.836186e+11  3.321078e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.212054e+05  5.325586e+05  5.762879e+05   \n",
       "R2                                8.861416e-02  4.847734e-02 -1.142007e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.764243e+05      2.742141e+05   \n",
       "Error Cuadrado Promedio                  3.037660e+11      2.998091e+11   \n",
       "Raíz del Error Cuadrado Promedio         5.511497e+05      5.475483e+05   \n",
       "R2                                      -1.911587e-02     -5.840715e-03   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.764097e+05         2.760766e+05   \n",
       "Error Cuadrado Promedio           3.037465e+11         2.855807e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.511320e+05         5.343975e+05   \n",
       "R2                               -1.905040e-02         4.189473e-02   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     3.122055e+05       2.729002e+05   \n",
       "Error Cuadrado Promedio                     3.953708e+11       3.012276e+11   \n",
       "Raíz del Error Cuadrado Promedio            6.287851e+05       5.488420e+05   \n",
       "R2                                         -3.264441e-01      -1.059967e-02   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.667584e+05  \n",
       "Error Cuadrado Promedio           2.846350e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.335120e+05  \n",
       "R2                                4.506730e-02  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "x360eure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "x360eure.to_csv('x360eure.csv')\n",
    "x360eure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37\n",
      "[LightGBM] [Info] Number of data points in the train set: 203, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 35270.935961\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = x360jp['Calificacion_critica']\n",
    "y = x360jp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.419458e+04</td>\n",
       "      <td>2.371957e+04</td>\n",
       "      <td>2.181783e+04</td>\n",
       "      <td>2.704104e+04</td>\n",
       "      <td>2.634667e+04</td>\n",
       "      <td>2.670002e+04</td>\n",
       "      <td>2.647727e+04</td>\n",
       "      <td>3.300978e+04</td>\n",
       "      <td>2.639466e+04</td>\n",
       "      <td>2.489828e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>1.182172e+09</td>\n",
       "      <td>1.157622e+09</td>\n",
       "      <td>1.447651e+09</td>\n",
       "      <td>1.485214e+09</td>\n",
       "      <td>1.408255e+09</td>\n",
       "      <td>1.474973e+09</td>\n",
       "      <td>1.381409e+09</td>\n",
       "      <td>2.329180e+09</td>\n",
       "      <td>1.401267e+09</td>\n",
       "      <td>1.195185e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>3.438273e+04</td>\n",
       "      <td>3.402385e+04</td>\n",
       "      <td>3.804801e+04</td>\n",
       "      <td>3.853848e+04</td>\n",
       "      <td>3.752672e+04</td>\n",
       "      <td>3.840537e+04</td>\n",
       "      <td>3.716731e+04</td>\n",
       "      <td>4.826158e+04</td>\n",
       "      <td>3.743350e+04</td>\n",
       "      <td>3.457145e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>4.871984e-02</td>\n",
       "      <td>6.847479e-02</td>\n",
       "      <td>-1.649079e-01</td>\n",
       "      <td>-1.951348e-01</td>\n",
       "      <td>-1.332062e-01</td>\n",
       "      <td>-1.868936e-01</td>\n",
       "      <td>-1.116040e-01</td>\n",
       "      <td>-8.742643e-01</td>\n",
       "      <td>-1.275831e-01</td>\n",
       "      <td>3.824839e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.419458e+04  2.371957e+04  2.181783e+04   \n",
       "Error Cuadrado Promedio           1.182172e+09  1.157622e+09  1.447651e+09   \n",
       "Raíz del Error Cuadrado Promedio  3.438273e+04  3.402385e+04  3.804801e+04   \n",
       "R2                                4.871984e-02  6.847479e-02 -1.649079e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.704104e+04      2.634667e+04   \n",
       "Error Cuadrado Promedio                  1.485214e+09      1.408255e+09   \n",
       "Raíz del Error Cuadrado Promedio         3.853848e+04      3.752672e+04   \n",
       "R2                                      -1.951348e-01     -1.332062e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.670002e+04         2.647727e+04   \n",
       "Error Cuadrado Promedio           1.474973e+09         1.381409e+09   \n",
       "Raíz del Error Cuadrado Promedio  3.840537e+04         3.716731e+04   \n",
       "R2                               -1.868936e-01        -1.116040e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     3.300978e+04       2.639466e+04   \n",
       "Error Cuadrado Promedio                     2.329180e+09       1.401267e+09   \n",
       "Raíz del Error Cuadrado Promedio            4.826158e+04       3.743350e+04   \n",
       "R2                                         -8.742643e-01      -1.275831e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.489828e+04  \n",
       "Error Cuadrado Promedio           1.195185e+09  \n",
       "Raíz del Error Cuadrado Promedio  3.457145e+04  \n",
       "R2                                3.824839e-02  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "x360jpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "x360jpre.to_csv('x360jpre.csv')\n",
    "x360jpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 62\n",
      "[LightGBM] [Info] Number of data points in the train set: 630, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 570841.269841\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = x360na['Calificacion_critica']\n",
    "y = x360na['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>6.235783e+05</td>\n",
       "      <td>5.945671e+05</td>\n",
       "      <td>5.655284e+05</td>\n",
       "      <td>5.235271e+05</td>\n",
       "      <td>5.197425e+05</td>\n",
       "      <td>5.234872e+05</td>\n",
       "      <td>5.258672e+05</td>\n",
       "      <td>6.774069e+05</td>\n",
       "      <td>5.157788e+05</td>\n",
       "      <td>5.278849e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.031654e+12</td>\n",
       "      <td>1.975604e+12</td>\n",
       "      <td>2.393860e+12</td>\n",
       "      <td>1.898217e+12</td>\n",
       "      <td>1.887137e+12</td>\n",
       "      <td>1.898175e+12</td>\n",
       "      <td>1.924820e+12</td>\n",
       "      <td>2.656064e+12</td>\n",
       "      <td>1.893250e+12</td>\n",
       "      <td>1.954571e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.425361e+06</td>\n",
       "      <td>1.405562e+06</td>\n",
       "      <td>1.547211e+06</td>\n",
       "      <td>1.377758e+06</td>\n",
       "      <td>1.373731e+06</td>\n",
       "      <td>1.377743e+06</td>\n",
       "      <td>1.387379e+06</td>\n",
       "      <td>1.629744e+06</td>\n",
       "      <td>1.375954e+06</td>\n",
       "      <td>1.398060e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>7.576748e-02</td>\n",
       "      <td>1.012655e-01</td>\n",
       "      <td>-8.900604e-02</td>\n",
       "      <td>1.364704e-01</td>\n",
       "      <td>1.415109e-01</td>\n",
       "      <td>1.364894e-01</td>\n",
       "      <td>1.243679e-01</td>\n",
       "      <td>-2.082867e-01</td>\n",
       "      <td>1.387298e-01</td>\n",
       "      <td>1.108340e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           6.235783e+05  5.945671e+05  5.655284e+05   \n",
       "Error Cuadrado Promedio           2.031654e+12  1.975604e+12  2.393860e+12   \n",
       "Raíz del Error Cuadrado Promedio  1.425361e+06  1.405562e+06  1.547211e+06   \n",
       "R2                                7.576748e-02  1.012655e-01 -8.900604e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  5.235271e+05      5.197425e+05   \n",
       "Error Cuadrado Promedio                  1.898217e+12      1.887137e+12   \n",
       "Raíz del Error Cuadrado Promedio         1.377758e+06      1.373731e+06   \n",
       "R2                                       1.364704e-01      1.415109e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           5.234872e+05         5.258672e+05   \n",
       "Error Cuadrado Promedio           1.898175e+12         1.924820e+12   \n",
       "Raíz del Error Cuadrado Promedio  1.377743e+06         1.387379e+06   \n",
       "R2                                1.364894e-01         1.243679e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     6.774069e+05       5.157788e+05   \n",
       "Error Cuadrado Promedio                     2.656064e+12       1.893250e+12   \n",
       "Raíz del Error Cuadrado Promedio            1.629744e+06       1.375954e+06   \n",
       "R2                                         -2.082867e-01       1.387298e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           5.278849e+05  \n",
       "Error Cuadrado Promedio           1.954571e+12  \n",
       "Raíz del Error Cuadrado Promedio  1.398060e+06  \n",
       "R2                                1.108340e-01  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "x360nare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "x360nare.to_csv('x360nare.csv')\n",
    "x360nare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 473, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 81162.790698\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = xbeu['Calificacion_critica']\n",
    "y = xbeu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>7.926969e+04</td>\n",
       "      <td>7.450469e+04</td>\n",
       "      <td>6.510223e+04</td>\n",
       "      <td>7.363718e+04</td>\n",
       "      <td>7.365736e+04</td>\n",
       "      <td>7.338325e+04</td>\n",
       "      <td>7.648276e+04</td>\n",
       "      <td>7.930248e+04</td>\n",
       "      <td>7.156896e+04</td>\n",
       "      <td>7.754564e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.129447e+10</td>\n",
       "      <td>2.023430e+10</td>\n",
       "      <td>2.560382e+10</td>\n",
       "      <td>1.878906e+10</td>\n",
       "      <td>1.874288e+10</td>\n",
       "      <td>1.877053e+10</td>\n",
       "      <td>1.913767e+10</td>\n",
       "      <td>3.009435e+10</td>\n",
       "      <td>1.851537e+10</td>\n",
       "      <td>2.144478e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>1.459262e+05</td>\n",
       "      <td>1.422473e+05</td>\n",
       "      <td>1.600119e+05</td>\n",
       "      <td>1.370732e+05</td>\n",
       "      <td>1.369046e+05</td>\n",
       "      <td>1.370056e+05</td>\n",
       "      <td>1.383390e+05</td>\n",
       "      <td>1.734772e+05</td>\n",
       "      <td>1.360712e+05</td>\n",
       "      <td>1.464404e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.074472e-01</td>\n",
       "      <td>1.518839e-01</td>\n",
       "      <td>-7.317800e-02</td>\n",
       "      <td>2.124610e-01</td>\n",
       "      <td>2.143967e-01</td>\n",
       "      <td>2.132377e-01</td>\n",
       "      <td>1.978488e-01</td>\n",
       "      <td>-2.613979e-01</td>\n",
       "      <td>2.239324e-01</td>\n",
       "      <td>1.011471e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           7.926969e+04  7.450469e+04  6.510223e+04   \n",
       "Error Cuadrado Promedio           2.129447e+10  2.023430e+10  2.560382e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.459262e+05  1.422473e+05  1.600119e+05   \n",
       "R2                                1.074472e-01  1.518839e-01 -7.317800e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  7.363718e+04      7.365736e+04   \n",
       "Error Cuadrado Promedio                  1.878906e+10      1.874288e+10   \n",
       "Raíz del Error Cuadrado Promedio         1.370732e+05      1.369046e+05   \n",
       "R2                                       2.124610e-01      2.143967e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           7.338325e+04         7.648276e+04   \n",
       "Error Cuadrado Promedio           1.877053e+10         1.913767e+10   \n",
       "Raíz del Error Cuadrado Promedio  1.370056e+05         1.383390e+05   \n",
       "R2                                2.132377e-01         1.978488e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     7.930248e+04       7.156896e+04   \n",
       "Error Cuadrado Promedio                     3.009435e+10       1.851537e+10   \n",
       "Raíz del Error Cuadrado Promedio            1.734772e+05       1.360712e+05   \n",
       "R2                                         -2.613979e-01       2.239324e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           7.754564e+04  \n",
       "Error Cuadrado Promedio           2.144478e+10  \n",
       "Raíz del Error Cuadrado Promedio  1.464404e+05  \n",
       "R2                                1.011471e-01  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "xbeure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "xbeure.to_csv('xbeure.csv')\n",
    "xbeure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 17, number of used features: 0\n",
      "[LightGBM] [Info] Start training from score 47647.058824\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = xbjp['Calificacion_critica']\n",
    "y = xbjp['Ventas_japonesas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>4.741708e+04</td>\n",
       "      <td>6.683545e+04</td>\n",
       "      <td>2.375051e+04</td>\n",
       "      <td>3.375000e+04</td>\n",
       "      <td>3.657542e+04</td>\n",
       "      <td>2.875000e+04</td>\n",
       "      <td>4.300000e+04</td>\n",
       "      <td>4.844411e+04</td>\n",
       "      <td>3.371520e+04</td>\n",
       "      <td>2.566176e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>3.884124e+09</td>\n",
       "      <td>8.039253e+09</td>\n",
       "      <td>1.712625e+09</td>\n",
       "      <td>2.662500e+09</td>\n",
       "      <td>2.767374e+09</td>\n",
       "      <td>2.512500e+09</td>\n",
       "      <td>3.016000e+09</td>\n",
       "      <td>3.708306e+09</td>\n",
       "      <td>2.658698e+09</td>\n",
       "      <td>1.362154e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>6.232274e+04</td>\n",
       "      <td>8.966188e+04</td>\n",
       "      <td>4.138388e+04</td>\n",
       "      <td>5.159942e+04</td>\n",
       "      <td>5.260584e+04</td>\n",
       "      <td>5.012484e+04</td>\n",
       "      <td>5.491812e+04</td>\n",
       "      <td>6.089586e+04</td>\n",
       "      <td>5.156256e+04</td>\n",
       "      <td>3.690737e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-1.854006e+00</td>\n",
       "      <td>-4.907143e+00</td>\n",
       "      <td>-2.584158e-01</td>\n",
       "      <td>-9.563720e-01</td>\n",
       "      <td>-1.033432e+00</td>\n",
       "      <td>-8.461539e-01</td>\n",
       "      <td>-1.216119e+00</td>\n",
       "      <td>-1.724817e+00</td>\n",
       "      <td>-9.535783e-01</td>\n",
       "      <td>-8.938539e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           4.741708e+04  6.683545e+04  2.375051e+04   \n",
       "Error Cuadrado Promedio           3.884124e+09  8.039253e+09  1.712625e+09   \n",
       "Raíz del Error Cuadrado Promedio  6.232274e+04  8.966188e+04  4.138388e+04   \n",
       "R2                               -1.854006e+00 -4.907143e+00 -2.584158e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  3.375000e+04      3.657542e+04   \n",
       "Error Cuadrado Promedio                  2.662500e+09      2.767374e+09   \n",
       "Raíz del Error Cuadrado Promedio         5.159942e+04      5.260584e+04   \n",
       "R2                                      -9.563720e-01     -1.033432e+00   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.875000e+04         4.300000e+04   \n",
       "Error Cuadrado Promedio           2.512500e+09         3.016000e+09   \n",
       "Raíz del Error Cuadrado Promedio  5.012484e+04         5.491812e+04   \n",
       "R2                               -8.461539e-01        -1.216119e+00   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     4.844411e+04       3.371520e+04   \n",
       "Error Cuadrado Promedio                     3.708306e+09       2.658698e+09   \n",
       "Raíz del Error Cuadrado Promedio            6.089586e+04       5.156256e+04   \n",
       "R2                                         -1.724817e+00      -9.535783e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.566176e+04  \n",
       "Error Cuadrado Promedio           1.362154e+09  \n",
       "Raíz del Error Cuadrado Promedio  3.690737e+04  \n",
       "R2                               -8.938539e-04  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "xbjpre = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "xbjpre.to_csv('xbjpre.csv')\n",
    "xbjpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 56\n",
      "[LightGBM] [Info] Number of data points in the train set: 507, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 223293.885602\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = xbna['Calificacion_critica']\n",
    "y = xbna['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.153010e+05</td>\n",
       "      <td>1.982953e+05</td>\n",
       "      <td>2.032393e+05</td>\n",
       "      <td>1.874472e+05</td>\n",
       "      <td>1.889852e+05</td>\n",
       "      <td>1.874255e+05</td>\n",
       "      <td>1.932202e+05</td>\n",
       "      <td>2.575047e+05</td>\n",
       "      <td>1.856817e+05</td>\n",
       "      <td>1.966237e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.473837e+11</td>\n",
       "      <td>2.269202e+11</td>\n",
       "      <td>2.977390e+11</td>\n",
       "      <td>2.079756e+11</td>\n",
       "      <td>2.086683e+11</td>\n",
       "      <td>2.079678e+11</td>\n",
       "      <td>1.854793e+11</td>\n",
       "      <td>3.412829e+11</td>\n",
       "      <td>2.074930e+11</td>\n",
       "      <td>2.269357e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>4.973769e+05</td>\n",
       "      <td>4.763614e+05</td>\n",
       "      <td>5.456547e+05</td>\n",
       "      <td>4.560434e+05</td>\n",
       "      <td>4.568023e+05</td>\n",
       "      <td>4.560349e+05</td>\n",
       "      <td>4.306731e+05</td>\n",
       "      <td>5.841942e+05</td>\n",
       "      <td>4.555140e+05</td>\n",
       "      <td>4.763777e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.009219e-01</td>\n",
       "      <td>1.752934e-01</td>\n",
       "      <td>-8.208673e-02</td>\n",
       "      <td>2.441447e-01</td>\n",
       "      <td>2.416270e-01</td>\n",
       "      <td>2.441730e-01</td>\n",
       "      <td>3.259041e-01</td>\n",
       "      <td>-2.403402e-01</td>\n",
       "      <td>2.458985e-01</td>\n",
       "      <td>1.752371e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.153010e+05  1.982953e+05  2.032393e+05   \n",
       "Error Cuadrado Promedio           2.473837e+11  2.269202e+11  2.977390e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.973769e+05  4.763614e+05  5.456547e+05   \n",
       "R2                                1.009219e-01  1.752934e-01 -8.208673e-02   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  1.874472e+05      1.889852e+05   \n",
       "Error Cuadrado Promedio                  2.079756e+11      2.086683e+11   \n",
       "Raíz del Error Cuadrado Promedio         4.560434e+05      4.568023e+05   \n",
       "R2                                       2.441447e-01      2.416270e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           1.874255e+05         1.932202e+05   \n",
       "Error Cuadrado Promedio           2.079678e+11         1.854793e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.560349e+05         4.306731e+05   \n",
       "R2                                2.441730e-01         3.259041e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.575047e+05       1.856817e+05   \n",
       "Error Cuadrado Promedio                     3.412829e+11       2.074930e+11   \n",
       "Raíz del Error Cuadrado Promedio            5.841942e+05       4.555140e+05   \n",
       "R2                                         -2.403402e-01       2.458985e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           1.966237e+05  \n",
       "Error Cuadrado Promedio           2.269357e+11  \n",
       "Raíz del Error Cuadrado Promedio  4.763777e+05  \n",
       "R2                                1.752371e-01  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "xbnare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "xbnare.to_csv('xbnare.csv')\n",
    "xbnare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28\n",
      "[LightGBM] [Info] Number of data points in the train set: 109, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 290183.486239\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = xoneeu['Calificacion_critica']\n",
    "y = xoneeu['Ventas_europeas']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>2.210841e+05</td>\n",
       "      <td>2.148947e+05</td>\n",
       "      <td>1.678713e+05</td>\n",
       "      <td>2.292492e+05</td>\n",
       "      <td>2.221273e+05</td>\n",
       "      <td>2.285860e+05</td>\n",
       "      <td>2.137872e+05</td>\n",
       "      <td>2.273680e+05</td>\n",
       "      <td>2.197227e+05</td>\n",
       "      <td>2.192728e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>8.080575e+10</td>\n",
       "      <td>8.798190e+10</td>\n",
       "      <td>8.548808e+10</td>\n",
       "      <td>1.112827e+11</td>\n",
       "      <td>1.062518e+11</td>\n",
       "      <td>1.112215e+11</td>\n",
       "      <td>9.234689e+10</td>\n",
       "      <td>1.233323e+11</td>\n",
       "      <td>1.046914e+11</td>\n",
       "      <td>9.577894e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>2.842635e+05</td>\n",
       "      <td>2.966174e+05</td>\n",
       "      <td>2.923834e+05</td>\n",
       "      <td>3.335906e+05</td>\n",
       "      <td>3.259629e+05</td>\n",
       "      <td>3.334989e+05</td>\n",
       "      <td>3.038863e+05</td>\n",
       "      <td>3.511869e+05</td>\n",
       "      <td>3.235605e+05</td>\n",
       "      <td>3.094817e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>-1.278873e-01</td>\n",
       "      <td>-2.280522e-01</td>\n",
       "      <td>-1.932433e-01</td>\n",
       "      <td>-5.532845e-01</td>\n",
       "      <td>-4.830634e-01</td>\n",
       "      <td>-5.524311e-01</td>\n",
       "      <td>-2.889787e-01</td>\n",
       "      <td>-7.214729e-01</td>\n",
       "      <td>-4.612836e-01</td>\n",
       "      <td>-3.368832e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           2.210841e+05  2.148947e+05  1.678713e+05   \n",
       "Error Cuadrado Promedio           8.080575e+10  8.798190e+10  8.548808e+10   \n",
       "Raíz del Error Cuadrado Promedio  2.842635e+05  2.966174e+05  2.923834e+05   \n",
       "R2                               -1.278873e-01 -2.280522e-01 -1.932433e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  2.292492e+05      2.221273e+05   \n",
       "Error Cuadrado Promedio                  1.112827e+11      1.062518e+11   \n",
       "Raíz del Error Cuadrado Promedio         3.335906e+05      3.259629e+05   \n",
       "R2                                      -5.532845e-01     -4.830634e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           2.285860e+05         2.137872e+05   \n",
       "Error Cuadrado Promedio           1.112215e+11         9.234689e+10   \n",
       "Raíz del Error Cuadrado Promedio  3.334989e+05         3.038863e+05   \n",
       "R2                               -5.524311e-01        -2.889787e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     2.273680e+05       2.197227e+05   \n",
       "Error Cuadrado Promedio                     1.233323e+11       1.046914e+11   \n",
       "Raíz del Error Cuadrado Promedio            3.511869e+05       3.235605e+05   \n",
       "R2                                         -7.214729e-01      -4.612836e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           2.192728e+05  \n",
       "Error Cuadrado Promedio           9.577894e+10  \n",
       "Raíz del Error Cuadrado Promedio  3.094817e+05  \n",
       "R2                               -3.368832e-01  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "xoneeure = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "xoneeure.to_csv('xoneeure.csv')\n",
    "xoneeure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 28\n",
      "[LightGBM] [Info] Number of data points in the train set: 112, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 496428.571429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ursuz\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = xonena['Calificacion_critica']\n",
    "y = xonena['Ventas_norteamerica']\n",
    "\n",
    "x, y = np.array(X), np.array(y)\n",
    "x2 = x.reshape(-1, 1)\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x_, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "y_predln = ln.predict(X_test)\n",
    "\n",
    "ln2 = ln.fit(X_train2, y_train2)\n",
    "y_predln2 = ln2.predict(X_test2)\n",
    "\n",
    "svmm = svm.SVR()\n",
    "svmm.fit(X_train, y_train)\n",
    "y_predsvm = svmm.predict(X_test)\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_preddtr = dtr.predict(X_test)\n",
    " \n",
    "rfr = RandomForestRegressor(random_state=1)\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predrfr = rfr.predict(X_test)\n",
    "\n",
    "clf = XGBRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "y_predclf = clf.predict(X_test)\n",
    "\n",
    "knr = KNeighborsRegressor()\n",
    "knr.fit(X_train, y_train)\n",
    "y_predknr = knr.predict(X_test)\n",
    "\n",
    "nnmlp = MLPRegressor()\n",
    "nnmlp.fit(X_train, y_train)\n",
    "y_prednnmlp = nnmlp.predict(X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train, y_train)\n",
    "y_predgbr = gbr.predict(X_test)\n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train, y_train)\n",
    "y_predlgbm = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lineal</th>\n",
       "      <th>Polinomial</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Arboles de Decisión</th>\n",
       "      <th>Bosque Aleatorio</th>\n",
       "      <th>XGBOOST</th>\n",
       "      <th>K-Nearest Neighbors</th>\n",
       "      <th>Multi-Layer Perceptron</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>LIGHTGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error Promedio Absoluto</th>\n",
       "      <td>3.274599e+05</td>\n",
       "      <td>3.168073e+05</td>\n",
       "      <td>3.294859e+05</td>\n",
       "      <td>4.033707e+05</td>\n",
       "      <td>3.918371e+05</td>\n",
       "      <td>4.035330e+05</td>\n",
       "      <td>3.697959e+05</td>\n",
       "      <td>4.182391e+05</td>\n",
       "      <td>3.933636e+05</td>\n",
       "      <td>3.565626e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Error Cuadrado Promedio</th>\n",
       "      <td>2.061310e+11</td>\n",
       "      <td>2.163574e+11</td>\n",
       "      <td>2.795295e+11</td>\n",
       "      <td>3.433653e+11</td>\n",
       "      <td>3.252978e+11</td>\n",
       "      <td>3.432973e+11</td>\n",
       "      <td>2.814611e+11</td>\n",
       "      <td>4.129880e+11</td>\n",
       "      <td>3.319821e+11</td>\n",
       "      <td>2.727873e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raíz del Error Cuadrado Promedio</th>\n",
       "      <td>4.540165e+05</td>\n",
       "      <td>4.651424e+05</td>\n",
       "      <td>5.287055e+05</td>\n",
       "      <td>5.859738e+05</td>\n",
       "      <td>5.703488e+05</td>\n",
       "      <td>5.859158e+05</td>\n",
       "      <td>5.305290e+05</td>\n",
       "      <td>6.426414e+05</td>\n",
       "      <td>5.761789e+05</td>\n",
       "      <td>5.222904e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>1.342301e-01</td>\n",
       "      <td>9.127806e-02</td>\n",
       "      <td>-1.740508e-01</td>\n",
       "      <td>-4.421673e-01</td>\n",
       "      <td>-3.662819e-01</td>\n",
       "      <td>-4.418817e-01</td>\n",
       "      <td>-1.821635e-01</td>\n",
       "      <td>-7.345893e-01</td>\n",
       "      <td>-3.943566e-01</td>\n",
       "      <td>-1.457328e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Lineal    Polinomial           SVM  \\\n",
       "Error Promedio Absoluto           3.274599e+05  3.168073e+05  3.294859e+05   \n",
       "Error Cuadrado Promedio           2.061310e+11  2.163574e+11  2.795295e+11   \n",
       "Raíz del Error Cuadrado Promedio  4.540165e+05  4.651424e+05  5.287055e+05   \n",
       "R2                                1.342301e-01  9.127806e-02 -1.740508e-01   \n",
       "\n",
       "                                  Arboles de Decisión  Bosque Aleatorio  \\\n",
       "Error Promedio Absoluto                  4.033707e+05      3.918371e+05   \n",
       "Error Cuadrado Promedio                  3.433653e+11      3.252978e+11   \n",
       "Raíz del Error Cuadrado Promedio         5.859738e+05      5.703488e+05   \n",
       "R2                                      -4.421673e-01     -3.662819e-01   \n",
       "\n",
       "                                       XGBOOST  K-Nearest Neighbors  \\\n",
       "Error Promedio Absoluto           4.035330e+05         3.697959e+05   \n",
       "Error Cuadrado Promedio           3.432973e+11         2.814611e+11   \n",
       "Raíz del Error Cuadrado Promedio  5.859158e+05         5.305290e+05   \n",
       "R2                               -4.418817e-01        -1.821635e-01   \n",
       "\n",
       "                                  Multi-Layer Perceptron  Gradient Boosting  \\\n",
       "Error Promedio Absoluto                     4.182391e+05       3.933636e+05   \n",
       "Error Cuadrado Promedio                     4.129880e+11       3.319821e+11   \n",
       "Raíz del Error Cuadrado Promedio            6.426414e+05       5.761789e+05   \n",
       "R2                                         -7.345893e-01      -3.943566e-01   \n",
       "\n",
       "                                      LIGHTGBM  \n",
       "Error Promedio Absoluto           3.565626e+05  \n",
       "Error Cuadrado Promedio           2.727873e+11  \n",
       "Raíz del Error Cuadrado Promedio  5.222904e+05  \n",
       "R2                               -1.457328e-01  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('LINEAL')\n",
    "resultado_lineal_mae = metrics.mean_absolute_error(y_test, y_predln)\n",
    "resultado_lineal_mse = metrics.mean_squared_error(y_test, y_predln)\n",
    "resultado_lineal_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predln))\n",
    "resultado_lineal_r2 = r2_score(y_test, y_predln)\n",
    "\n",
    "#print('POLINOMIAL')\n",
    "resultado_polinomial_mae = metrics.mean_absolute_error(y_test2, y_predln2)\n",
    "resultado_polinomial_mse = metrics.mean_squared_error(y_test2, y_predln2)\n",
    "resultado_polinomial_rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_predln2))\n",
    "resultado_polinomial_r2 = r2_score(y_test2, y_predln2)\n",
    "\n",
    "#print('SUPPORT MACHINE VECTOR')\n",
    "resultado_svm_mae = metrics.mean_absolute_error(y_test, y_predsvm)\n",
    "resultado_svm_mse = metrics.mean_squared_error(y_test, y_predsvm)\n",
    "resultado_svm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predsvm))\n",
    "resultado_svm_r2 = r2_score(y_test, y_predsvm)\n",
    "\n",
    "#print('DECISION TREE')\n",
    "resultado_dt_mae = metrics.mean_absolute_error(y_test, y_preddtr)\n",
    "resultado_dt_mse = metrics.mean_squared_error(y_test, y_preddtr)\n",
    "resultado_dt_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_preddtr))\n",
    "resultado_dt_r2 = r2_score(y_test, y_preddtr)\n",
    "\n",
    "#print('RANDOM FOREST')\n",
    "resultado_rf_mae = metrics.mean_absolute_error(y_test, y_predrfr)\n",
    "resultado_rf_mse = metrics.mean_squared_error(y_test, y_predrfr)\n",
    "resultado_rf_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predrfr))\n",
    "resultado_rf_r2 = r2_score(y_test, y_predrfr)\n",
    "\n",
    "#print('EXTREME GRADIENT BOOSTING (XGBOOST)')\n",
    "resultado_xgboost_mae = metrics.mean_absolute_error(y_test, y_predclf)\n",
    "resultado_xgboost_mse = metrics.mean_squared_error(y_test, y_predclf)\n",
    "resultado_xgboost_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predclf))\n",
    "resultado_xgboost_r2 = r2_score(y_test, y_predclf)\n",
    "\n",
    "#print('K-NEAREST NEIGHBORS')\n",
    "resultado_knn_mae = metrics.mean_absolute_error(y_test, y_predknr)\n",
    "resultado_knn_mse = metrics.mean_squared_error(y_test, y_predknr)\n",
    "resultado_knn_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predknr))\n",
    "resultado_knn_r2 = r2_score(y_test, y_predknr)\n",
    "\n",
    "#print('MULTI-LAYER PERCEPTRON REGRESSOR')\n",
    "resultado_mlp_mae = metrics.mean_absolute_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_mse = metrics.mean_squared_error(y_test, y_prednnmlp)\n",
    "resultado_mlp_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_prednnmlp))\n",
    "resultado_mlp_r2 = r2_score(y_test, y_prednnmlp)\n",
    "\n",
    "#print('GRADIENT BOOSTING')\n",
    "resultado_gb_mae = metrics.mean_absolute_error(y_test, y_predgbr)\n",
    "resultado_gb_mse = metrics.mean_squared_error(y_test, y_predgbr)\n",
    "resultado_gb_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predgbr))\n",
    "resultado_gb_r2 = r2_score(y_test, y_predgbr)\n",
    "\n",
    "#print('LIGHTGBM')\n",
    "resultado_lightgbm_mae = metrics.mean_absolute_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_mse = metrics.mean_squared_error(y_test, y_predlgbm)\n",
    "resultado_lightgbm_rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predlgbm))\n",
    "resultado_lightgbm_r2 = r2_score(y_test, y_predlgbm)\n",
    "\n",
    "# Crear un diccionario con los resultados de cada modelo\n",
    "resultados = {\n",
    "    'Lineal': [resultado_lineal_mae, resultado_lineal_mse, resultado_lineal_rmse, resultado_lineal_r2],\n",
    "    'Polinomial': [resultado_polinomial_mae, resultado_polinomial_mse, resultado_polinomial_rmse, resultado_polinomial_r2],\n",
    "    'SVM': [resultado_svm_mae, resultado_svm_mse, resultado_svm_rmse, resultado_svm_r2],\n",
    "    'Arboles de Decisión': [resultado_dt_mae, resultado_dt_mse, resultado_dt_rmse, resultado_dt_r2],\n",
    "    'Bosque Aleatorio': [resultado_rf_mae, resultado_rf_mse, resultado_rf_rmse, resultado_rf_r2],\n",
    "    'XGBOOST': [resultado_xgboost_mae, resultado_xgboost_mse, resultado_xgboost_rmse, resultado_xgboost_r2],\n",
    "    'K-Nearest Neighbors': [resultado_knn_mae, resultado_knn_mse, resultado_knn_rmse, resultado_knn_r2],\n",
    "    'Multi-Layer Perceptron': [resultado_mlp_mae, resultado_mlp_mse, resultado_mlp_rmse, resultado_mlp_r2],\n",
    "    'Gradient Boosting': [resultado_gb_mae, resultado_gb_mse, resultado_gb_rmse, resultado_gb_r2],\n",
    "    'LIGHTGBM': [resultado_lightgbm_mae, resultado_lightgbm_mse, resultado_lightgbm_rmse, resultado_lightgbm_r2]\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "xonenare = pd.DataFrame(resultados, index=['Error Promedio Absoluto', 'Error Cuadrado Promedio', 'Raíz del Error Cuadrado Promedio', 'R2'])\n",
    "\n",
    "# Mostrar el DataFrame y guardar en CSV\n",
    "xonenare.to_csv('xonenare.csv')\n",
    "xonenare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
